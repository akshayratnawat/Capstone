{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be5d05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the directories\n",
    "#!ls /d/KWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5621d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls /d/KWS/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba49682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the feaures in the feat_librosa folder\n",
    "#!tar -xvf  '/d/KWS/data/feat_compressed.tar' -C '/d/KWS/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45304cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ebec66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required Libraries\n",
    "import torch\n",
    "#import librosa\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6686c7c0",
   "metadata": {},
   "source": [
    "##### Creating Train and Test Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b67071bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Training and Testing data\n",
    "# feat_shape = 512\n",
    "# root = 'D:/KWS/data/'\n",
    "# feat_folder = os.path.join(root, 'feat')\n",
    "\n",
    "# lst = sorted(os.listdir(feat_folder))\n",
    "\n",
    "# labels = [d for d in lst if os.path.isdir(os.path.join(feat_folder, d))\n",
    "#           and d[0].isalpha()]\n",
    "\n",
    "# train_samples = [0 for label in labels]\n",
    "# test_samples = [0 for label in labels]\n",
    "\n",
    "# #count train-test first\n",
    "# for i, label in enumerate(labels):\n",
    "#     record_list = sorted(os.listdir(os.path.join(feat_folder, label)))\n",
    "#     for r, record_name in enumerate(record_list):\n",
    "#         if hash(record_name) % 10 < 9:\n",
    "#             train_samples[i] += 1\n",
    "#         else:\n",
    "#             test_samples[i] += 1\n",
    "\n",
    "# for i, label in tqdm(enumerate(labels)):    \n",
    "#     record_list = sorted(os.listdir(os.path.join(feat_folder, label)))\n",
    "#     time_s = time.time()\n",
    "#     train_count = 0\n",
    "#     test_count = 0\n",
    "#     train_data_class = np.full((train_samples[i], 1), i, dtype=np.uint8)\n",
    "#     train_data_in = np.empty((train_samples[i], feat_shape, 100), dtype=np.float)\n",
    "#     test_data_class = np.full((test_samples[i], 1), i, dtype=np.uint8)\n",
    "#     test_data_in = np.empty((test_samples[i], feat_shape, 100), dtype=np.float)\n",
    "\n",
    "#     for r, record_name in enumerate(record_list):\n",
    "#         time_s = time.time()\n",
    "#         record_pth = os.path.join(feat_folder, label, record_name)\n",
    "        \n",
    "#         record = np.squeeze(np.load(record_pth))      \n",
    "#         if hash(record_name) % 10 < 9:\n",
    "#             train_data_in[train_count, :] = record           \n",
    "#             train_count += 1\n",
    "                \n",
    "#         else:\n",
    "#             test_data_in[test_count, :] = record\n",
    "#             test_count += 1\n",
    "\n",
    " \n",
    "#     if i == 0:\n",
    "\n",
    "#         train_data_in_all = train_data_in.copy()\n",
    "#         train_data_class_all = train_data_class.copy()\n",
    "#         test_data_in_all = test_data_in.copy()\n",
    "#         test_data_class_all = test_data_class.copy()\n",
    "#     else:\n",
    "\n",
    "#         train_data_in_all = np.concatenate((train_data_in_all, train_data_in), axis=0)\n",
    "#         train_data_class_all = np.concatenate((train_data_class_all, train_data_class), axis=0)    \n",
    "#         test_data_in_all = np.concatenate((test_data_in_all, test_data_in), axis=0)\n",
    "#         test_data_class_all = np.concatenate((test_data_class_all, test_data_class), axis=0)  \n",
    "\n",
    "#     dur = time.time() - time_s\n",
    "#     if i == 19: #THIS WAS INTENTIONALLY CUT SHORT FOR THE SAKE OF SPPED IN POC BUILDING\n",
    "#         break\n",
    "# print(train_data_in_all.shape)\n",
    "# print(test_data_in_all.shape)\n",
    "# print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90838c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = []\n",
    "# for i in range(len(train_data_in_all)):\n",
    "#    train_data.append([train_data_in_all[i], train_data_class_all[i]])\n",
    "\n",
    "# with open(\"D:/KWS/data/train_data.txt\", \"wb\") as fp:   #Pickling\n",
    "#     pickle.dump(train_data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b22718c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = []\n",
    "# for i in range(len(test_data_in_all)):\n",
    "#    test_data.append([test_data_in_all[i], test_data_class_all[i]])\n",
    "\n",
    "# with open(\"test_data.txt\", \"wb\") as fp:   #Pickling\n",
    "#     pickle.dump(test_data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14afb31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the train and test data\n",
    "with open(\"train_data.txt\", \"rb\") as fp:   # Unpickling\n",
    "    train_data = pickle.load(fp)\n",
    "    \n",
    "with open(\"test_data.txt\", \"rb\") as fp:   # Unpickling\n",
    "    test_data = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41a5c487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046cf214",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(train_data[0:2048]).size * np.array(train_data[0:2048]).itemsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82b32a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish epoch  0 total loss 318.480 accuracy 0.876\n",
      "Finish epoch  1 total loss 157.282 accuracy 0.934\n",
      "Finish epoch  2 total loss 128.662 accuracy 0.946\n",
      "Finish epoch  3 total loss 116.693 accuracy 0.950\n",
      "Finish epoch  4 total loss 102.865 accuracy 0.956\n",
      "Finish epoch  5 total loss 93.051 accuracy 0.960\n",
      "Finish epoch  6 total loss 83.815 accuracy 0.964\n",
      "Finish epoch  7 total loss 77.427 accuracy 0.966\n",
      "Finish epoch  8 total loss 73.087 accuracy 0.968\n",
      "Finish epoch  9 total loss 66.494 accuracy 0.971\n",
      "Finish epoch  10 total loss 59.755 accuracy 0.974\n",
      "Finish epoch  11 total loss 58.026 accuracy 0.974\n",
      "Finish epoch  12 total loss 53.753 accuracy 0.976\n",
      "Finish epoch  13 total loss 46.522 accuracy 0.980\n",
      "Finish epoch  14 total loss 46.842 accuracy 0.980\n",
      "Finish epoch  15 total loss 44.004 accuracy 0.981\n",
      "Finish epoch  16 total loss 39.025 accuracy 0.984\n",
      "Finish epoch  17 total loss 40.287 accuracy 0.983\n",
      "Finish epoch  18 total loss 33.514 accuracy 0.986\n",
      "Finish epoch  19 total loss 33.904 accuracy 0.985\n",
      "Finish epoch  20 total loss 29.970 accuracy 0.987\n",
      "Finish epoch  21 total loss 29.929 accuracy 0.987\n",
      "Finish epoch  22 total loss 27.002 accuracy 0.988\n",
      "Finish epoch  23 total loss 33.057 accuracy 0.986\n",
      "Finish epoch  24 total loss 23.469 accuracy 0.990\n",
      "Finish epoch  25 total loss 28.588 accuracy 0.987\n",
      "Finish epoch  26 total loss 22.806 accuracy 0.990\n",
      "Finish epoch  27 total loss 23.943 accuracy 0.990\n",
      "Finish epoch  28 total loss 20.675 accuracy 0.991\n",
      "Finish epoch  29 total loss 20.567 accuracy 0.992\n",
      "Finish epoch  30 total loss 21.637 accuracy 0.991\n",
      "Finish epoch  31 total loss 19.559 accuracy 0.992\n",
      "Finish epoch  32 total loss 16.995 accuracy 0.993\n",
      "Finish epoch  33 total loss 19.832 accuracy 0.992\n",
      "Finish epoch  34 total loss 17.457 accuracy 0.993\n",
      "Finish epoch  35 total loss 15.733 accuracy 0.994\n",
      "Finish epoch  36 total loss 17.507 accuracy 0.993\n",
      "Finish epoch  37 total loss 12.886 accuracy 0.995\n",
      "Finish epoch  38 total loss 13.586 accuracy 0.995\n",
      "Finish epoch  39 total loss 12.892 accuracy 0.995\n",
      "Finish epoch  40 total loss 13.170 accuracy 0.995\n",
      "Finish epoch  41 total loss 15.174 accuracy 0.994\n",
      "Finish epoch  42 total loss 12.369 accuracy 0.995\n",
      "Finish epoch  43 total loss 10.086 accuracy 0.996\n",
      "Finish epoch  44 total loss 13.634 accuracy 0.995\n",
      "Finish epoch  45 total loss 11.303 accuracy 0.995\n",
      "Finish epoch  46 total loss 9.197 accuracy 0.996\n",
      "Finish epoch  47 total loss 7.525 accuracy 0.997\n",
      "Finish epoch  48 total loss 12.962 accuracy 0.995\n",
      "Finish epoch  49 total loss 10.103 accuracy 0.996\n",
      "Finish epoch  50 total loss 9.295 accuracy 0.997\n",
      "Finish epoch  51 total loss 9.368 accuracy 0.996\n",
      "Finish epoch  52 total loss 8.761 accuracy 0.997\n",
      "Finish epoch  53 total loss 7.731 accuracy 0.997\n",
      "Finish epoch  54 total loss 9.503 accuracy 0.997\n",
      "Finish epoch  55 total loss 7.340 accuracy 0.997\n",
      "Finish epoch  56 total loss 10.132 accuracy 0.996\n",
      "Finish epoch  57 total loss 6.225 accuracy 0.998\n",
      "Finish epoch  58 total loss 8.389 accuracy 0.997\n",
      "Finish epoch  59 total loss 8.884 accuracy 0.997\n",
      "Finish epoch  60 total loss 5.120 accuracy 0.998\n",
      "Finish epoch  61 total loss 5.428 accuracy 0.998\n",
      "Finish epoch  62 total loss 8.903 accuracy 0.997\n",
      "Finish epoch  63 total loss 7.981 accuracy 0.997\n",
      "Finish epoch  64 total loss 6.222 accuracy 0.998\n",
      "Finish epoch  65 total loss 6.683 accuracy 0.997\n",
      "Finish epoch  66 total loss 3.858 accuracy 0.998\n",
      "Finish epoch  67 total loss 4.848 accuracy 0.998\n",
      "Finish epoch  68 total loss 6.811 accuracy 0.997\n",
      "Finish epoch  69 total loss 7.024 accuracy 0.997\n",
      "Finish epoch  70 total loss 6.425 accuracy 0.998\n",
      "Finish epoch  71 total loss 5.224 accuracy 0.998\n",
      "Finish epoch  72 total loss 5.545 accuracy 0.998\n",
      "Finish epoch  73 total loss 6.555 accuracy 0.998\n",
      "Finish epoch  74 total loss 4.913 accuracy 0.998\n",
      "Finish epoch  75 total loss 5.687 accuracy 0.998\n",
      "Finish epoch  76 total loss 5.407 accuracy 0.998\n",
      "Finish epoch  77 total loss 4.363 accuracy 0.998\n",
      "Finish epoch  78 total loss 5.486 accuracy 0.998\n",
      "Finish epoch  79 total loss 3.779 accuracy 0.998\n",
      "Finish epoch  80 total loss 4.040 accuracy 0.998\n",
      "Finish epoch  81 total loss 5.689 accuracy 0.998\n",
      "Finish epoch  82 total loss 4.763 accuracy 0.998\n",
      "Finish epoch  83 total loss 4.319 accuracy 0.999\n",
      "Finish epoch  84 total loss 4.562 accuracy 0.998\n",
      "Finish epoch  85 total loss 6.157 accuracy 0.998\n",
      "Finish epoch  86 total loss 3.924 accuracy 0.999\n",
      "Finish epoch  87 total loss 2.817 accuracy 0.999\n",
      "Finish epoch  88 total loss 5.777 accuracy 0.998\n",
      "Finish epoch  89 total loss 4.310 accuracy 0.998\n",
      "Finish epoch  90 total loss 4.592 accuracy 0.999\n",
      "Finish epoch  91 total loss 5.568 accuracy 0.998\n",
      "Finish epoch  92 total loss 3.863 accuracy 0.998\n",
      "Finish epoch  93 total loss 5.009 accuracy 0.998\n",
      "Finish epoch  94 total loss 2.968 accuracy 0.999\n",
      "Finish epoch  95 total loss 4.584 accuracy 0.998\n",
      "Finish epoch  96 total loss 2.869 accuracy 0.999\n",
      "Finish epoch  97 total loss 5.316 accuracy 0.998\n",
      "Finish epoch  98 total loss 3.077 accuracy 0.999\n",
      "Finish epoch  99 total loss 4.569 accuracy 0.998\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total loss 30.514 accuracy 0.958\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, lr, epochs, batch_size, num_classes= 20):\n",
    "        super(CNN, self).__init__()\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.num_classes = num_classes\n",
    "        self.loss_history = []\n",
    "        self.acc_history = []\n",
    "        self.device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(512, 128, 9)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(128, 128, 9)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(128, 96, 9)\n",
    "        self.bn3 = nn.BatchNorm1d(96)\n",
    "        \n",
    "        self.maxpool1 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.conv4 = nn.Conv1d(96, 64, 3)\n",
    "        self.bn4 = nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.maxpool2 = nn.MaxPool1d(2)\n",
    "\n",
    "        input_dims = self.calc_input_dims()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_dims, self.num_classes)\n",
    "\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        self.to(self.device)\n",
    "        self.get_data()\n",
    "\n",
    "    def calc_input_dims(self):\n",
    "        batch_data = T.zeros((1, 512, 100))\n",
    "        batch_data = self.conv1(batch_data)\n",
    "        #batch_data = self.bn1(batch_data)\n",
    "        batch_data = self.conv2(batch_data)\n",
    "        #batch_data = self.bn2(batch_data)\n",
    "        batch_data = self.conv3(batch_data)\n",
    "\n",
    "        batch_data = self.maxpool1(batch_data)\n",
    "        batch_data = self.conv4(batch_data)\n",
    "        batch_data = self.maxpool2(batch_data)\n",
    "\n",
    "        return int(np.prod(batch_data.size()))\n",
    "\n",
    "    def forward(self, batch_data):\n",
    "        batch_data = T.tensor(batch_data).to(self.device, dtype=torch.float )\n",
    "\n",
    "        batch_data = self.conv1(batch_data)\n",
    "        batch_data = self.bn1(batch_data)\n",
    "        batch_data = F.relu(batch_data)\n",
    "\n",
    "        batch_data = self.conv2(batch_data)\n",
    "        batch_data = self.bn2(batch_data)\n",
    "        batch_data = F.relu(batch_data)\n",
    "\n",
    "        batch_data = self.conv3(batch_data)\n",
    "        batch_data = self.bn3(batch_data)\n",
    "        batch_data = F.relu(batch_data)\n",
    "\n",
    "        batch_data = self.maxpool1(batch_data)\n",
    "\n",
    "        batch_data = self.conv4(batch_data)\n",
    "        batch_data = self.bn4(batch_data)\n",
    "        batch_data = F.relu(batch_data)\n",
    "\n",
    "        batch_data = self.maxpool2(batch_data)\n",
    "\n",
    "        batch_data = batch_data.view(batch_data.size()[0], -1)\n",
    "\n",
    "        classes = self.fc1(batch_data)\n",
    "\n",
    "        return classes\n",
    "\n",
    "\n",
    "    def get_data(self):\n",
    "        self.train_data_loader = T.utils.data.DataLoader(train_data,\n",
    "                                                    batch_size=self.batch_size,\n",
    "                                                    shuffle=True,\n",
    "                                                    num_workers=8)\n",
    "\n",
    "        self.test_data_loader = T.utils.data.DataLoader(test_data,\n",
    "                                                    batch_size=self.batch_size,\n",
    "                                                    shuffle=True,\n",
    "                                                    num_workers=8)\n",
    "\n",
    "    def _train(self):\n",
    "        self.train()\n",
    "        for i in range(self.epochs):\n",
    "            ep_loss = 0\n",
    "            ep_acc = []\n",
    "            for j, (input, label) in enumerate(self.train_data_loader):\n",
    "                self.optimizer.zero_grad()\n",
    "                label = label.to(self.device).type(torch.LongTensor)           \n",
    "                prediction = self.forward(input)\n",
    "            \n",
    "                \n",
    "                \n",
    "                loss = self.loss(prediction, label.flatten().to(self.device))\n",
    "                \n",
    "                \n",
    "                prediction = F.softmax(prediction, dim=1)\n",
    "                \n",
    "                classes = T.argmax(prediction, dim=1)\n",
    "                \n",
    "                wrong = T.where(classes != label.flatten().to(self.device),\n",
    "                                T.tensor([1.]).to(self.device, dtype=torch.float),\n",
    "                                T.tensor([0.]).to(self.device, dtype=torch.float))\n",
    "                \n",
    "                acc = 1 - T.sum(wrong) / self.batch_size\n",
    "\n",
    "                ep_acc.append(acc.item())\n",
    "                self.acc_history.append(acc.item())\n",
    "                ep_loss += loss.item()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "            print('Finish epoch ', i, 'total loss %.3f' % ep_loss,\n",
    "                    'accuracy %.3f' % np.mean(ep_acc))\n",
    "            self.loss_history.append(ep_loss)\n",
    "\n",
    "    def _test(self):\n",
    "        self.eval()\n",
    "\n",
    "        ep_loss = 0\n",
    "        ep_acc = []\n",
    "        for j, (input, label) in enumerate(self.test_data_loader):\n",
    "            label = label.to(self.device).type(torch.LongTensor)            \n",
    "            prediction = self.forward(input)                \n",
    "            loss = self.loss(prediction, label.flatten().to(self.device))\n",
    "            prediction = F.softmax(prediction, dim=1)\n",
    "            classes = T.argmax(prediction, dim=1)\n",
    "            wrong = T.where(classes != label.flatten().to(self.device),\n",
    "                            T.tensor([1.]).to(self.device, dtype=torch.float),\n",
    "                            T.tensor([0.]).to(self.device, dtype=torch.float))\n",
    "            acc = 1 - T.sum(wrong) / self.batch_size\n",
    "\n",
    "            ep_acc.append(acc.item())\n",
    "\n",
    "            ep_loss += loss.item()\n",
    "\n",
    "        print('total loss %.3f' % ep_loss,\n",
    "                'accuracy %.3f' % np.mean(ep_acc))\n",
    "\n",
    "# Running the model\n",
    "if __name__ == '__main__':\n",
    "    network = CNN(lr=0.001, batch_size= 64, epochs=100)\n",
    "    network._train()\n",
    "    plt.plot(network.loss_history)\n",
    "    plt.show()\n",
    "    plt.plot(network.acc_history)\n",
    "    plt.show()\n",
    "    network._test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac22b0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "conv1.weight \t torch.Size([128, 512, 9])\n",
      "conv1.bias \t torch.Size([128])\n",
      "bn1.weight \t torch.Size([128])\n",
      "bn1.bias \t torch.Size([128])\n",
      "bn1.running_mean \t torch.Size([128])\n",
      "bn1.running_var \t torch.Size([128])\n",
      "bn1.num_batches_tracked \t torch.Size([])\n",
      "conv2.weight \t torch.Size([128, 128, 9])\n",
      "conv2.bias \t torch.Size([128])\n",
      "bn2.weight \t torch.Size([128])\n",
      "bn2.bias \t torch.Size([128])\n",
      "bn2.running_mean \t torch.Size([128])\n",
      "bn2.running_var \t torch.Size([128])\n",
      "bn2.num_batches_tracked \t torch.Size([])\n",
      "conv3.weight \t torch.Size([96, 128, 9])\n",
      "conv3.bias \t torch.Size([96])\n",
      "bn3.weight \t torch.Size([96])\n",
      "bn3.bias \t torch.Size([96])\n",
      "bn3.running_mean \t torch.Size([96])\n",
      "bn3.running_var \t torch.Size([96])\n",
      "bn3.num_batches_tracked \t torch.Size([])\n",
      "conv4.weight \t torch.Size([64, 96, 3])\n",
      "conv4.bias \t torch.Size([64])\n",
      "bn4.weight \t torch.Size([64])\n",
      "bn4.bias \t torch.Size([64])\n",
      "bn4.running_mean \t torch.Size([64])\n",
      "bn4.running_var \t torch.Size([64])\n",
      "bn4.num_batches_tracked \t torch.Size([])\n",
      "fc1.weight \t torch.Size([20, 1152])\n",
      "fc1.bias \t torch.Size([20])\n",
      "Optimizer's state_dict:\n",
      "state \t {0: {'step': 75600, 'exp_avg': tensor([[[-4.4082e-07,  1.8624e-08, -1.8512e-07,  ..., -8.1288e-07,\n",
      "          -9.9261e-07, -1.1321e-06],\n",
      "         [ 2.3885e-06,  2.7020e-06,  2.9901e-06,  ...,  3.1284e-06,\n",
      "           2.8757e-06,  2.3768e-06],\n",
      "         [ 8.9671e-06,  1.1432e-05,  1.4365e-05,  ...,  1.8086e-05,\n",
      "           1.6718e-05,  1.4840e-05],\n",
      "         ...,\n",
      "         [-1.9671e-07, -1.3353e-07, -3.8306e-08,  ...,  1.5103e-07,\n",
      "           1.6971e-07,  2.3798e-07],\n",
      "         [-5.1037e-06, -4.8799e-06, -5.2810e-06,  ..., -8.8602e-06,\n",
      "          -8.5300e-06, -8.4287e-06],\n",
      "         [ 7.0623e-06,  6.8935e-06,  7.5079e-06,  ...,  9.1025e-06,\n",
      "           1.0440e-05,  1.1940e-05]],\n",
      "\n",
      "        [[ 9.6583e-07,  8.7618e-07,  7.5033e-07,  ...,  2.3497e-07,\n",
      "           4.6162e-07,  6.8040e-07],\n",
      "         [ 2.4044e-07,  1.3179e-07,  8.1518e-08,  ...,  3.0517e-07,\n",
      "           4.4190e-07,  5.2592e-07],\n",
      "         [ 4.9956e-06,  5.0213e-06,  5.4729e-06,  ...,  1.0934e-05,\n",
      "           1.2363e-05,  1.3314e-05],\n",
      "         ...,\n",
      "         [-7.9324e-07, -6.9912e-07, -5.9462e-07,  ...,  7.5373e-07,\n",
      "           1.1652e-06,  1.2069e-06],\n",
      "         [ 5.4539e-06,  6.4299e-06,  8.0195e-06,  ...,  1.1740e-05,\n",
      "           1.2195e-05,  1.2686e-05],\n",
      "         [-2.0580e-06, -3.4586e-06, -4.1403e-06,  ..., -9.7674e-06,\n",
      "          -1.2544e-05, -1.5359e-05]],\n",
      "\n",
      "        [[ 3.2312e-06,  3.0153e-06,  2.2765e-06,  ...,  2.4729e-07,\n",
      "           1.4613e-07,  4.1203e-07],\n",
      "         [-6.6262e-07, -4.3633e-08,  8.5609e-07,  ...,  2.4683e-06,\n",
      "           2.5878e-06,  2.0262e-06],\n",
      "         [ 7.9363e-06,  9.6219e-06,  1.0956e-05,  ...,  1.2107e-05,\n",
      "           1.0989e-05,  7.0092e-06],\n",
      "         ...,\n",
      "         [ 9.5385e-09, -1.0816e-06, -2.0907e-06,  ..., -3.4079e-06,\n",
      "          -3.0647e-06, -2.5782e-06],\n",
      "         [ 2.5925e-05,  2.5453e-05,  2.5550e-05,  ...,  3.2266e-05,\n",
      "           3.4288e-05,  3.4250e-05],\n",
      "         [ 6.6178e-06,  1.5338e-06,  4.7356e-07,  ...,  2.8063e-06,\n",
      "           3.6927e-06,  4.4937e-06]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 6.1554e-07,  5.9687e-07,  5.3639e-07,  ..., -5.9827e-07,\n",
      "          -2.5989e-07,  3.1992e-07],\n",
      "         [ 1.5902e-06,  2.2174e-06,  2.2693e-06,  ...,  7.4466e-07,\n",
      "           6.1482e-07,  3.1526e-07],\n",
      "         [-7.3898e-06, -9.1993e-06, -9.7198e-06,  ..., -9.5984e-06,\n",
      "          -9.3083e-06, -1.0425e-05],\n",
      "         ...,\n",
      "         [ 1.3217e-06,  1.1992e-06,  7.4050e-07,  ..., -4.7440e-07,\n",
      "          -2.1122e-07,  1.9088e-07],\n",
      "         [ 1.3916e-06, -1.0895e-06, -3.3741e-06,  ..., -2.1557e-06,\n",
      "          -3.3968e-06, -3.9770e-06],\n",
      "         [-9.8389e-06, -9.3431e-06, -8.2458e-06,  ...,  6.3228e-06,\n",
      "           9.6122e-06,  1.0857e-05]],\n",
      "\n",
      "        [[-1.3924e-07, -4.4093e-08,  3.3125e-08,  ..., -1.0223e-08,\n",
      "          -6.4341e-08, -9.8750e-08],\n",
      "         [ 2.6101e-06,  2.1492e-06,  1.4817e-06,  ...,  7.7205e-07,\n",
      "           1.7849e-06,  1.8748e-06],\n",
      "         [-1.7228e-05, -1.7570e-05, -1.5632e-05,  ...,  2.0050e-06,\n",
      "           9.7201e-06,  1.7055e-05],\n",
      "         ...,\n",
      "         [ 2.1156e-07,  3.2644e-07,  3.8986e-07,  ...,  1.2659e-07,\n",
      "           1.4560e-07,  2.1317e-07],\n",
      "         [-1.2742e-05, -1.3588e-05, -1.4418e-05,  ..., -1.0776e-05,\n",
      "          -9.3788e-06, -7.2422e-06],\n",
      "         [ 6.4313e-06,  6.6428e-06,  6.6254e-06,  ...,  5.7576e-06,\n",
      "           5.2629e-06,  4.8307e-06]],\n",
      "\n",
      "        [[ 2.5472e-06,  2.6704e-06,  2.8680e-06,  ...,  3.2503e-06,\n",
      "           3.7663e-06,  2.4131e-06],\n",
      "         [ 6.1204e-07,  3.3497e-07,  6.8543e-07,  ...,  1.1820e-06,\n",
      "           1.0329e-06,  8.4650e-07],\n",
      "         [ 1.2405e-05,  1.1084e-05,  1.3526e-05,  ...,  1.2391e-05,\n",
      "           1.5768e-05,  2.1516e-05],\n",
      "         ...,\n",
      "         [-2.4125e-06, -2.4902e-06, -2.5613e-06,  ..., -1.1484e-06,\n",
      "          -1.8894e-07,  3.1563e-07],\n",
      "         [-8.1144e-07, -2.1205e-06, -1.9137e-06,  ...,  5.2185e-06,\n",
      "           5.4846e-06,  4.2220e-06],\n",
      "         [-3.4467e-06, -3.2425e-06, -3.4350e-06,  ...,  4.7365e-07,\n",
      "           2.4409e-07, -9.5830e-07]]]), 'exp_avg_sq': tensor([[[1.2239e-10, 1.1909e-10, 1.1967e-10,  ..., 1.4565e-10,\n",
      "          1.6307e-10, 1.7667e-10],\n",
      "         [1.8659e-10, 2.0146e-10, 2.0893e-10,  ..., 1.5408e-10,\n",
      "          1.3743e-10, 1.2279e-10],\n",
      "         [1.2442e-08, 1.2411e-08, 1.2383e-08,  ..., 1.0933e-08,\n",
      "          1.0909e-08, 1.1123e-08],\n",
      "         ...,\n",
      "         [3.9930e-11, 3.5421e-11, 3.5628e-11,  ..., 3.3650e-11,\n",
      "          3.3628e-11, 3.1368e-11],\n",
      "         [2.0925e-08, 2.0869e-08, 2.1053e-08,  ..., 2.0789e-08,\n",
      "          2.0364e-08, 1.9746e-08],\n",
      "         [4.7630e-09, 4.6667e-09, 4.5156e-09,  ..., 3.5339e-09,\n",
      "          3.6010e-09, 3.7897e-09]],\n",
      "\n",
      "        [[5.5194e-11, 5.1845e-11, 4.8873e-11,  ..., 6.3868e-11,\n",
      "          6.7306e-11, 7.1929e-11],\n",
      "         [8.3115e-11, 7.8032e-11, 7.1501e-11,  ..., 3.2035e-11,\n",
      "          3.0187e-11, 3.0282e-11],\n",
      "         [5.5141e-09, 5.0656e-09, 4.7457e-09,  ..., 4.0432e-09,\n",
      "          4.0379e-09, 4.0876e-09],\n",
      "         ...,\n",
      "         [3.6748e-11, 3.5768e-11, 3.4413e-11,  ..., 3.6561e-11,\n",
      "          3.8841e-11, 4.0536e-11],\n",
      "         [3.3681e-09, 3.5426e-09, 3.7728e-09,  ..., 5.0142e-09,\n",
      "          5.3849e-09, 5.7865e-09],\n",
      "         [2.8015e-09, 2.8468e-09, 2.8922e-09,  ..., 2.9115e-09,\n",
      "          2.8422e-09, 2.7682e-09]],\n",
      "\n",
      "        [[8.1573e-11, 8.6382e-11, 9.8208e-11,  ..., 1.2695e-10,\n",
      "          1.1799e-10, 1.1679e-10],\n",
      "         [2.3044e-10, 2.6979e-10, 3.0222e-10,  ..., 1.3579e-10,\n",
      "          1.1903e-10, 1.0870e-10],\n",
      "         [7.5052e-09, 7.8206e-09, 7.9901e-09,  ..., 7.2423e-09,\n",
      "          7.0376e-09, 7.0833e-09],\n",
      "         ...,\n",
      "         [2.5358e-11, 2.4686e-11, 2.6450e-11,  ..., 1.9326e-11,\n",
      "          1.7119e-11, 1.7052e-11],\n",
      "         [9.2292e-09, 8.2919e-09, 7.3725e-09,  ..., 4.9065e-09,\n",
      "          4.6699e-09, 4.5646e-09],\n",
      "         [3.4474e-09, 3.4266e-09, 3.2667e-09,  ..., 3.2852e-09,\n",
      "          3.5779e-09, 3.8907e-09]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.2975e-10, 1.1607e-10, 1.0617e-10,  ..., 1.0231e-10,\n",
      "          1.1686e-10, 1.2728e-10],\n",
      "         [2.3954e-10, 2.4836e-10, 2.4361e-10,  ..., 1.6904e-10,\n",
      "          1.1842e-10, 8.7584e-11],\n",
      "         [7.3176e-09, 7.6904e-09, 8.0701e-09,  ..., 9.1022e-09,\n",
      "          9.0178e-09, 8.8258e-09],\n",
      "         ...,\n",
      "         [3.3012e-11, 3.6164e-11, 4.1305e-11,  ..., 6.2442e-11,\n",
      "          5.8204e-11, 5.2838e-11],\n",
      "         [8.7136e-09, 8.9630e-09, 9.2922e-09,  ..., 9.5499e-09,\n",
      "          9.7964e-09, 1.0149e-08],\n",
      "         [3.9908e-09, 3.8994e-09, 3.7793e-09,  ..., 3.6553e-09,\n",
      "          3.7765e-09, 3.9437e-09]],\n",
      "\n",
      "        [[9.2707e-11, 1.0913e-10, 1.1919e-10,  ..., 1.2397e-10,\n",
      "          1.2668e-10, 1.3133e-10],\n",
      "         [2.9480e-10, 3.4661e-10, 3.2025e-10,  ..., 9.2738e-11,\n",
      "          9.9813e-11, 1.0660e-10],\n",
      "         [1.1607e-08, 1.1999e-08, 1.1687e-08,  ..., 1.0383e-08,\n",
      "          1.0828e-08, 1.1375e-08],\n",
      "         ...,\n",
      "         [3.8041e-11, 3.9824e-11, 4.1727e-11,  ..., 4.1033e-11,\n",
      "          3.9096e-11, 3.5957e-11],\n",
      "         [1.7785e-08, 1.8114e-08, 1.8486e-08,  ..., 1.9289e-08,\n",
      "          1.9203e-08, 1.8947e-08],\n",
      "         [3.6756e-09, 3.8406e-09, 4.0494e-09,  ..., 3.6496e-09,\n",
      "          3.5118e-09, 3.4635e-09]],\n",
      "\n",
      "        [[3.0413e-10, 3.2602e-10, 3.3746e-10,  ..., 3.3539e-10,\n",
      "          3.6148e-10, 3.9221e-10],\n",
      "         [7.7521e-10, 8.1448e-10, 8.0518e-10,  ..., 2.7497e-10,\n",
      "          2.2983e-10, 2.0606e-10],\n",
      "         [3.2165e-08, 3.1560e-08, 3.0899e-08,  ..., 2.5961e-08,\n",
      "          2.4950e-08, 2.4346e-08],\n",
      "         ...,\n",
      "         [9.9967e-11, 9.3983e-11, 9.4056e-11,  ..., 1.2241e-10,\n",
      "          1.3823e-10, 1.5335e-10],\n",
      "         [3.2846e-08, 3.3272e-08, 3.3663e-08,  ..., 3.8617e-08,\n",
      "          4.0213e-08, 4.1352e-08],\n",
      "         [1.5575e-08, 1.5522e-08, 1.5908e-08,  ..., 2.0353e-08,\n",
      "          2.1832e-08, 2.2599e-08]]])}, 1: {'step': 75600, 'exp_avg': tensor([-4.6184e-11,  8.0443e-12, -2.8608e-10,  3.5823e-11,  2.6703e-11,\n",
      "         5.1356e-11,  1.1921e-11, -9.7619e-11, -1.0789e-10,  6.8602e-11,\n",
      "        -1.2924e-10, -7.9243e-12,  3.8332e-10,  4.6022e-11,  6.3659e-12,\n",
      "        -1.3037e-10,  1.9599e-11, -6.8527e-11,  2.3439e-11, -2.9918e-11,\n",
      "         2.8301e-12, -3.2749e-11,  6.8295e-12,  3.2115e-11, -4.5664e-11,\n",
      "        -6.7995e-11, -3.7835e-11,  9.7571e-11,  1.2698e-10, -6.8417e-11,\n",
      "         2.5230e-11, -1.6309e-10,  6.1188e-11, -5.1512e-11, -1.1301e-11,\n",
      "         6.5374e-11,  6.2310e-11, -4.3847e-11, -3.7395e-11,  1.4535e-10,\n",
      "        -5.3217e-11,  1.6185e-11, -2.2460e-11, -1.5334e-11,  3.0981e-11,\n",
      "         7.6832e-11, -4.7324e-11,  1.3084e-10,  2.7247e-11, -2.0148e-11,\n",
      "        -3.4310e-11,  6.2033e-11, -1.2036e-11,  5.1794e-10, -8.1001e-12,\n",
      "        -1.9065e-10, -1.9776e-11,  7.0951e-13, -1.9042e-11,  5.3901e-11,\n",
      "        -4.0565e-11,  4.3632e-11, -8.7069e-12, -1.0506e-11,  1.6251e-11,\n",
      "         3.0846e-11, -5.9779e-11, -2.0328e-12,  3.1044e-11,  9.5037e-12,\n",
      "        -1.5748e-10, -2.1460e-11,  1.1227e-10,  1.7053e-11, -1.9164e-11,\n",
      "        -1.1773e-11, -5.4486e-11,  3.4626e-11, -9.2737e-11, -1.3730e-11,\n",
      "        -1.5943e-11,  1.5852e-12, -1.0816e-10, -2.8310e-11, -2.8002e-12,\n",
      "        -3.0361e-11, -3.9460e-12,  4.5252e-11,  1.0574e-11,  1.7778e-10,\n",
      "         7.1676e-11, -4.3701e-11, -3.7755e-11, -8.1403e-11, -5.4066e-11,\n",
      "         7.2369e-11, -1.0237e-10, -2.3224e-11, -7.5124e-11,  3.4637e-12,\n",
      "         8.6042e-11,  5.8219e-12, -3.3505e-10,  6.1163e-11,  9.5757e-11,\n",
      "         9.4176e-11, -2.6656e-11, -3.6253e-11, -6.9873e-11, -1.7828e-10,\n",
      "         2.2803e-10, -5.4830e-12,  1.6661e-11, -1.5609e-10,  2.3669e-11,\n",
      "         4.3681e-12,  2.0980e-12,  1.0510e-10,  6.4449e-11, -2.6397e-11,\n",
      "         2.7847e-11,  4.7011e-11,  4.5542e-11,  6.0675e-11, -3.8742e-11,\n",
      "         1.7732e-11,  6.8251e-11, -1.1504e-10]), 'exp_avg_sq': tensor([2.7344e-19, 8.6876e-20, 1.7325e-19, 2.0698e-19, 1.2305e-19, 9.7702e-20,\n",
      "        5.9613e-20, 2.9869e-19, 3.0301e-19, 3.5475e-19, 1.1522e-19, 2.0203e-19,\n",
      "        7.6029e-19, 2.3102e-19, 1.4599e-19, 2.1412e-19, 2.3612e-19, 1.6840e-19,\n",
      "        6.2611e-20, 1.7671e-19, 1.9535e-19, 1.2705e-19, 8.2320e-20, 1.5065e-19,\n",
      "        3.0954e-19, 1.2046e-19, 2.2670e-19, 6.6589e-19, 1.8466e-19, 7.0026e-20,\n",
      "        1.0127e-19, 4.3498e-19, 1.6400e-19, 3.8616e-19, 1.0516e-19, 1.8981e-19,\n",
      "        2.3449e-19, 1.6222e-18, 1.1138e-19, 9.6248e-20, 1.4007e-19, 8.2512e-20,\n",
      "        5.0005e-20, 1.2245e-19, 2.1480e-19, 1.8272e-19, 6.8030e-20, 1.1590e-19,\n",
      "        1.0687e-19, 9.2256e-20, 2.2970e-19, 1.1775e-18, 2.9883e-19, 5.7636e-19,\n",
      "        2.8922e-19, 6.2294e-19, 1.1295e-19, 7.6430e-20, 1.1856e-19, 3.8384e-20,\n",
      "        1.8828e-19, 3.0882e-19, 5.0307e-20, 1.5426e-19, 4.3146e-19, 1.5239e-19,\n",
      "        3.7144e-19, 1.7099e-19, 2.8048e-19, 4.4772e-20, 2.3991e-19, 3.8368e-19,\n",
      "        5.0006e-19, 1.1935e-19, 5.0521e-19, 8.8644e-20, 1.2522e-19, 1.2161e-19,\n",
      "        2.1409e-19, 2.0520e-19, 1.4505e-19, 3.0127e-19, 2.9617e-19, 1.6737e-19,\n",
      "        3.2671e-19, 2.2323e-19, 1.3142e-19, 1.2382e-19, 1.5820e-19, 1.1328e-19,\n",
      "        1.2611e-19, 8.5893e-20, 8.6910e-20, 3.8514e-19, 1.5303e-19, 2.6004e-19,\n",
      "        1.7848e-19, 5.7327e-20, 1.8600e-19, 6.7951e-20, 1.3481e-19, 1.2672e-19,\n",
      "        3.2408e-19, 1.2401e-19, 3.9701e-20, 2.1700e-19, 1.4413e-19, 2.2129e-19,\n",
      "        3.7459e-19, 2.4322e-19, 2.0143e-19, 1.3787e-19, 2.6043e-19, 4.5480e-20,\n",
      "        2.9699e-19, 1.6345e-19, 1.9584e-19, 2.0217e-19, 5.5778e-20, 1.1012e-19,\n",
      "        1.2623e-19, 2.5604e-19, 9.5381e-20, 6.6653e-20, 2.3852e-19, 3.0997e-19,\n",
      "        3.4961e-19, 6.5675e-19])}, 2: {'step': 75600, 'exp_avg': tensor([-4.6317e-04, -4.7704e-04,  3.3857e-04, -7.6242e-04, -3.9459e-04,\n",
      "        -1.1988e-04, -3.2743e-04,  9.7309e-04,  3.1930e-04,  3.3219e-04,\n",
      "         6.0579e-04, -5.5625e-04, -1.6488e-03, -2.2604e-04, -3.6815e-04,\n",
      "        -1.8163e-03,  1.6746e-03, -4.8681e-04, -4.4560e-04,  3.7437e-04,\n",
      "        -3.8374e-04,  6.6255e-04, -5.8789e-04,  1.2110e-03, -1.0494e-05,\n",
      "         1.3750e-03,  7.7880e-04,  8.4080e-04,  4.8505e-04, -2.1609e-04,\n",
      "        -1.6131e-03,  8.5571e-04, -5.7383e-04,  2.1729e-03, -1.1389e-03,\n",
      "         9.7885e-04,  7.9180e-04,  8.4072e-04,  6.8308e-04, -1.3281e-03,\n",
      "        -1.6840e-04,  2.6022e-04,  2.7963e-04, -1.1171e-06,  2.9471e-04,\n",
      "         1.0138e-03, -7.0819e-04, -1.7734e-03, -4.5972e-04,  6.1282e-04,\n",
      "         8.2696e-04, -3.0570e-04, -2.1786e-04, -1.2043e-03,  1.0523e-03,\n",
      "         1.0718e-03, -5.5150e-04,  7.4819e-05, -1.2776e-04, -3.0434e-04,\n",
      "        -1.6455e-04,  8.6228e-04, -1.4555e-04,  3.9231e-04,  7.0837e-04,\n",
      "        -3.8697e-04,  2.4770e-04, -2.3519e-04, -2.3082e-04,  5.1199e-04,\n",
      "         6.8888e-04,  3.2540e-06, -1.0666e-03,  5.5917e-04, -5.2030e-04,\n",
      "         2.4991e-04, -3.4510e-04, -1.9541e-03, -9.0222e-04, -6.9924e-04,\n",
      "        -7.5681e-05, -4.4019e-04,  9.1100e-04,  7.5804e-05,  6.4182e-04,\n",
      "        -3.2585e-04, -1.8740e-03,  2.6781e-03, -6.4934e-04,  2.6962e-04,\n",
      "        -3.4639e-04, -1.8838e-03, -3.4377e-04,  3.9195e-04, -4.5520e-04,\n",
      "         6.8223e-05,  2.1145e-04,  4.8411e-04, -8.3022e-04, -5.5465e-04,\n",
      "        -2.2992e-04,  2.8691e-04, -7.2070e-04, -5.2485e-04, -5.8279e-04,\n",
      "         7.8646e-04, -3.5044e-04, -1.0730e-04, -4.3366e-04, -1.8581e-04,\n",
      "         2.5089e-03, -5.1284e-04, -8.5994e-04, -1.3200e-03,  9.2511e-05,\n",
      "        -1.1285e-03, -9.8288e-04, -6.3057e-04,  5.4522e-04, -7.1580e-04,\n",
      "         1.1116e-03,  1.0472e-03, -8.5579e-04, -7.1740e-04, -5.4754e-05,\n",
      "         6.6526e-05,  1.6779e-04,  7.4054e-05]), 'exp_avg_sq': tensor([1.9057e-05, 3.0925e-05, 3.4557e-05, 2.9896e-05, 1.5328e-05, 2.0622e-05,\n",
      "        1.4888e-05, 3.4700e-05, 2.0326e-05, 4.7384e-05, 1.8858e-05, 3.9646e-05,\n",
      "        1.9509e-05, 2.3382e-05, 4.7488e-05, 3.1214e-05, 3.1741e-05, 2.4274e-05,\n",
      "        2.9581e-05, 3.8925e-05, 2.4628e-05, 2.0619e-05, 2.1109e-05, 2.7185e-05,\n",
      "        4.1526e-05, 1.3269e-05, 2.4194e-05, 3.6807e-05, 2.0822e-05, 1.9410e-05,\n",
      "        3.9447e-05, 2.2995e-05, 2.5263e-05, 4.2487e-05, 2.2823e-05, 3.1750e-05,\n",
      "        1.9984e-05, 3.2836e-05, 2.8717e-05, 2.3607e-05, 6.0453e-05, 3.0328e-05,\n",
      "        2.4063e-05, 2.4457e-05, 3.6345e-05, 2.2208e-05, 1.4422e-05, 2.8052e-05,\n",
      "        3.6791e-05, 1.2324e-05, 2.3653e-05, 9.0680e-05, 4.8396e-05, 2.5563e-05,\n",
      "        3.6108e-05, 3.6740e-05, 1.1384e-05, 1.8364e-05, 1.6833e-05, 3.6771e-05,\n",
      "        2.1315e-05, 2.4017e-05, 2.6948e-05, 2.4445e-05, 3.0973e-05, 2.1208e-05,\n",
      "        1.5709e-05, 2.1025e-05, 2.7204e-05, 1.4666e-05, 2.6321e-05, 3.9230e-05,\n",
      "        3.0374e-05, 1.3413e-05, 3.4808e-05, 2.2126e-05, 1.8769e-05, 1.9941e-05,\n",
      "        2.6283e-05, 3.8513e-05, 1.6035e-05, 3.1736e-05, 2.1417e-05, 2.2451e-05,\n",
      "        3.6099e-05, 1.8947e-05, 3.3743e-05, 2.6554e-05, 2.0349e-05, 2.1929e-05,\n",
      "        2.3442e-05, 2.4606e-05, 1.4747e-05, 3.8536e-05, 1.5575e-05, 4.7101e-05,\n",
      "        2.5422e-05, 4.0858e-05, 6.4621e-05, 2.5954e-05, 2.1069e-05, 2.4868e-05,\n",
      "        3.0808e-05, 3.1404e-05, 1.9857e-05, 1.8682e-05, 1.7717e-05, 2.5617e-05,\n",
      "        5.1596e-05, 2.0037e-05, 4.3402e-05, 1.7452e-05, 3.3400e-05, 2.5209e-05,\n",
      "        2.3680e-05, 3.1652e-05, 3.0961e-05, 2.3234e-05, 2.4833e-05, 2.5341e-05,\n",
      "        2.8125e-05, 2.3436e-05, 3.9709e-05, 2.5967e-05, 3.5702e-05, 4.3141e-05,\n",
      "        3.0347e-05, 2.6503e-05])}, 3: {'step': 75600, 'exp_avg': tensor([-2.8554e-04, -7.2240e-04, -3.6379e-04, -4.0342e-04, -5.2428e-05,\n",
      "        -5.9634e-05, -2.4683e-04,  2.1616e-04, -3.3275e-04,  2.3769e-04,\n",
      "         5.7868e-04, -4.1365e-04,  4.1182e-05,  6.0458e-05, -4.3024e-04,\n",
      "        -9.0248e-04,  1.3309e-04, -5.1658e-04, -2.1173e-04,  4.0213e-04,\n",
      "        -1.1568e-04,  5.2826e-04, -7.7242e-04,  6.2640e-04, -5.4962e-04,\n",
      "         1.7020e-03,  2.8657e-04,  7.1534e-04,  3.0134e-04, -2.8603e-04,\n",
      "        -1.1283e-03,  7.8380e-04, -4.2315e-04,  1.2447e-03, -1.1880e-03,\n",
      "         2.0601e-04,  1.4479e-03, -2.4771e-04,  6.8515e-04, -6.8622e-04,\n",
      "        -3.1400e-04,  3.7712e-04,  6.7077e-06, -1.7889e-05, -2.0106e-05,\n",
      "         1.0750e-03, -5.4534e-04, -1.1557e-03, -4.3414e-04,  4.0218e-04,\n",
      "         5.9611e-04, -2.8399e-05, -5.4217e-04, -5.1665e-04,  5.0279e-04,\n",
      "        -9.6265e-05, -2.1598e-04,  4.2151e-05,  1.1751e-04, -1.0665e-04,\n",
      "        -1.6257e-05,  6.6756e-04, -1.0186e-04,  4.8308e-04,  4.6020e-04,\n",
      "        -3.2459e-04,  6.0467e-05, -3.8145e-04, -3.4503e-04,  5.6654e-04,\n",
      "         1.9081e-04, -6.7314e-05, -1.1513e-03,  4.4208e-04, -4.6329e-04,\n",
      "         2.1605e-04, -3.3248e-04, -1.2068e-03, -1.5818e-04, -3.6333e-04,\n",
      "         3.1284e-04, -1.3401e-04,  4.8587e-04,  6.4032e-04,  3.0585e-04,\n",
      "        -2.3889e-04, -7.9596e-04,  1.3504e-03, -5.5290e-04,  8.0532e-05,\n",
      "        -2.3298e-04, -1.5077e-03, -4.6089e-04,  6.7150e-04,  2.5794e-04,\n",
      "        -2.6376e-05, -2.6513e-04,  4.9126e-04, -1.1762e-03, -1.8849e-04,\n",
      "        -4.2767e-04,  2.6601e-04,  1.1832e-04, -4.5341e-04, -7.7504e-04,\n",
      "         8.8003e-04, -5.4991e-05, -8.5013e-05, -3.6847e-04, -6.4432e-04,\n",
      "         1.3621e-03, -4.3108e-04, -8.6438e-04, -9.1506e-04, -1.4789e-04,\n",
      "        -8.0347e-04, -7.2745e-04, -7.4655e-04,  1.8683e-04, -8.2770e-04,\n",
      "         1.1492e-03,  8.1000e-04, -4.6404e-04, -5.8193e-04,  1.1459e-04,\n",
      "         2.3667e-05,  1.6616e-04,  5.6841e-06]), 'exp_avg_sq': tensor([1.7497e-05, 1.8304e-05, 1.6875e-05, 1.6052e-05, 1.2634e-05, 1.9633e-05,\n",
      "        7.5736e-06, 1.7165e-05, 1.8915e-05, 1.6096e-05, 2.1513e-05, 1.4006e-05,\n",
      "        1.6237e-05, 1.2606e-05, 1.9913e-05, 1.5507e-05, 1.8001e-05, 1.2043e-05,\n",
      "        1.1598e-05, 1.4208e-05, 1.4777e-05, 1.5423e-05, 2.0344e-05, 1.0841e-05,\n",
      "        1.8675e-05, 1.5356e-05, 1.4126e-05, 1.9394e-05, 1.4342e-05, 9.9699e-06,\n",
      "        1.4761e-05, 1.3223e-05, 9.9058e-06, 1.4540e-05, 1.8111e-05, 1.6682e-05,\n",
      "        1.6678e-05, 1.5840e-05, 1.6668e-05, 1.3218e-05, 2.4764e-05, 1.7159e-05,\n",
      "        1.1171e-05, 1.5083e-05, 2.0213e-05, 1.5674e-05, 1.2246e-05, 2.1409e-05,\n",
      "        2.2162e-05, 1.3254e-05, 2.4404e-05, 3.2179e-05, 1.9842e-05, 1.6765e-05,\n",
      "        1.8216e-05, 1.3638e-05, 1.0677e-05, 1.4593e-05, 1.3410e-05, 1.6538e-05,\n",
      "        1.3185e-05, 1.1961e-05, 2.0124e-05, 1.3705e-05, 1.1156e-05, 1.6633e-05,\n",
      "        1.3347e-05, 1.5367e-05, 1.5227e-05, 1.2183e-05, 2.0578e-05, 2.1682e-05,\n",
      "        1.7386e-05, 1.1273e-05, 1.8622e-05, 9.9487e-06, 1.3667e-05, 1.7503e-05,\n",
      "        1.3476e-05, 1.5213e-05, 1.3188e-05, 1.4198e-05, 1.5184e-05, 1.4160e-05,\n",
      "        1.4927e-05, 1.6284e-05, 1.2507e-05, 1.5638e-05, 1.6131e-05, 1.5803e-05,\n",
      "        1.3600e-05, 1.4999e-05, 1.7058e-05, 1.6173e-05, 1.1098e-05, 1.7063e-05,\n",
      "        9.8095e-06, 1.9646e-05, 2.3981e-05, 1.5350e-05, 9.8710e-06, 1.9522e-05,\n",
      "        1.3767e-05, 1.3673e-05, 1.2375e-05, 1.3289e-05, 1.4316e-05, 1.1048e-05,\n",
      "        1.9462e-05, 1.2380e-05, 1.4651e-05, 1.1960e-05, 1.5706e-05, 1.4962e-05,\n",
      "        1.4505e-05, 3.5485e-05, 1.2325e-05, 1.7013e-05, 1.0123e-05, 1.9765e-05,\n",
      "        2.1075e-05, 1.5519e-05, 1.3825e-05, 1.4949e-05, 1.4855e-05, 1.9460e-05,\n",
      "        1.8381e-05, 2.0617e-05])}, 4: {'step': 75600, 'exp_avg': tensor([[[-7.5214e-06, -4.2470e-06,  2.9568e-07,  ...,  1.6524e-05,\n",
      "           1.7197e-05,  1.6253e-05],\n",
      "         [-9.7678e-06, -1.0143e-05, -9.6406e-06,  ...,  4.3695e-06,\n",
      "           9.3107e-06,  1.4050e-05],\n",
      "         [ 5.7813e-06,  8.5504e-06,  1.0632e-05,  ...,  9.7053e-06,\n",
      "           7.3516e-06,  5.1824e-06],\n",
      "         ...,\n",
      "         [-7.8239e-06, -7.9519e-06, -6.4931e-06,  ...,  1.3693e-05,\n",
      "           1.8013e-05,  2.0668e-05],\n",
      "         [-1.7150e-05, -1.1976e-05, -7.4261e-06,  ..., -2.3542e-06,\n",
      "          -3.6672e-06, -6.2309e-06],\n",
      "         [-1.0022e-05, -9.7777e-06, -7.7011e-06,  ...,  1.6746e-05,\n",
      "           2.4563e-05,  3.0849e-05]],\n",
      "\n",
      "        [[ 2.2487e-06,  5.1564e-07, -1.2325e-06,  ...,  4.1525e-06,\n",
      "           7.5511e-06,  9.7868e-06],\n",
      "         [-1.2094e-06, -1.9111e-06, -3.3957e-06,  ..., -7.9704e-06,\n",
      "          -6.2956e-06, -4.6362e-06],\n",
      "         [ 1.1126e-05,  1.3299e-05,  1.5556e-05,  ...,  1.2502e-05,\n",
      "           9.1498e-06,  6.1445e-06],\n",
      "         ...,\n",
      "         [-4.4246e-06, -6.4886e-06, -7.8277e-06,  ...,  4.3334e-06,\n",
      "           1.2416e-05,  2.1656e-05],\n",
      "         [ 7.0912e-06,  6.8911e-06,  6.9441e-06,  ...,  1.3542e-05,\n",
      "           1.3530e-05,  1.2716e-05],\n",
      "         [-1.5136e-05, -1.7565e-05, -1.9664e-05,  ..., -2.1990e-06,\n",
      "           7.1971e-06,  1.6256e-05]],\n",
      "\n",
      "        [[ 6.7329e-06,  6.5326e-06,  6.2859e-06,  ...,  4.9275e-06,\n",
      "           4.7278e-06,  4.7663e-06],\n",
      "         [ 5.2180e-06,  8.4916e-06,  1.0296e-05,  ...,  8.9187e-06,\n",
      "           7.9270e-06,  6.8474e-06],\n",
      "         [-5.1659e-07,  1.0159e-06,  2.1069e-06,  ...,  2.5727e-06,\n",
      "           2.4037e-06,  1.8181e-06],\n",
      "         ...,\n",
      "         [ 6.6822e-06,  6.3993e-06,  5.7954e-06,  ...,  1.5428e-06,\n",
      "           8.4099e-07,  7.2289e-07],\n",
      "         [ 2.3507e-06,  2.2771e-06,  2.2739e-06,  ...,  3.2123e-06,\n",
      "           3.7733e-06,  4.3997e-06],\n",
      "         [ 5.5779e-06,  5.2361e-06,  5.0799e-06,  ...,  5.2236e-06,\n",
      "           5.4424e-06,  5.9085e-06]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.4925e-06, -3.1544e-06, -5.0808e-06,  ..., -8.9488e-07,\n",
      "           2.7185e-06,  4.8173e-06],\n",
      "         [ 4.4880e-06,  5.3257e-06,  6.1907e-06,  ...,  9.6686e-06,\n",
      "           1.3111e-05,  1.8355e-05],\n",
      "         [ 5.7220e-05,  5.3571e-05,  5.0580e-05,  ...,  3.0201e-05,\n",
      "           2.2690e-05,  1.6589e-05],\n",
      "         ...,\n",
      "         [ 2.8898e-06, -1.0540e-06, -5.8976e-06,  ..., -1.6147e-05,\n",
      "          -1.4096e-05, -9.4920e-06],\n",
      "         [-2.1458e-05, -2.3284e-05, -2.4879e-05,  ..., -1.5824e-05,\n",
      "          -9.9744e-06, -3.9143e-06],\n",
      "         [ 7.2418e-06,  1.1531e-05,  1.4865e-05,  ...,  2.2695e-05,\n",
      "           3.0514e-05,  4.1621e-05]],\n",
      "\n",
      "        [[-6.6273e-07, -7.1253e-07, -7.8339e-07,  ..., -1.2760e-06,\n",
      "          -1.0001e-06, -8.0973e-07],\n",
      "         [ 4.8435e-06,  3.7802e-06,  2.4887e-06,  ..., -2.3624e-06,\n",
      "          -3.1129e-06, -3.5522e-06],\n",
      "         [ 6.7266e-07,  7.8707e-07,  8.2334e-07,  ...,  1.8131e-06,\n",
      "           1.7169e-06,  1.4452e-06],\n",
      "         ...,\n",
      "         [-1.9974e-06, -2.8408e-06, -3.5506e-06,  ..., -4.5638e-06,\n",
      "          -4.3924e-06, -3.8525e-06],\n",
      "         [ 1.0558e-05,  1.0773e-05,  1.0880e-05,  ...,  1.2279e-05,\n",
      "           1.2758e-05,  1.3237e-05],\n",
      "         [-2.6920e-07, -6.9494e-07, -1.2094e-06,  ..., -5.3128e-06,\n",
      "          -5.4963e-06, -4.6828e-06]],\n",
      "\n",
      "        [[-8.1216e-07, -3.9979e-06, -7.2903e-06,  ..., -6.9830e-06,\n",
      "          -3.9819e-06, -1.6385e-06],\n",
      "         [ 6.5295e-06,  8.3514e-06,  1.0106e-05,  ...,  1.4196e-05,\n",
      "           1.5180e-05,  1.6750e-05],\n",
      "         [ 1.8714e-06, -2.3273e-06, -6.0558e-06,  ..., -1.0892e-05,\n",
      "          -9.1692e-06, -6.1849e-06],\n",
      "         ...,\n",
      "         [ 9.8350e-06,  1.4891e-05,  1.9322e-05,  ...,  2.1929e-05,\n",
      "           2.0300e-05,  1.8749e-05],\n",
      "         [-3.5362e-06, -3.3461e-06, -3.3122e-06,  ..., -3.9854e-07,\n",
      "           1.7773e-06,  3.9074e-06],\n",
      "         [ 1.3926e-05,  1.4397e-05,  1.3729e-05,  ...,  1.6280e-05,\n",
      "           1.9589e-05,  2.2896e-05]]]), 'exp_avg_sq': tensor([[[3.3196e-08, 3.1542e-08, 3.0025e-08,  ..., 2.5632e-08,\n",
      "          2.4055e-08, 2.2128e-08],\n",
      "         [3.6870e-09, 4.1991e-09, 4.6740e-09,  ..., 5.7758e-09,\n",
      "          6.3063e-09, 7.1316e-09],\n",
      "         [8.7398e-09, 9.2425e-09, 1.0207e-08,  ..., 1.4830e-08,\n",
      "          1.5613e-08, 1.5842e-08],\n",
      "         ...,\n",
      "         [9.2814e-09, 1.1254e-08, 1.3435e-08,  ..., 2.0571e-08,\n",
      "          2.1833e-08, 2.3281e-08],\n",
      "         [2.2851e-08, 2.1710e-08, 2.0952e-08,  ..., 2.1150e-08,\n",
      "          2.1336e-08, 2.1172e-08],\n",
      "         [2.0733e-08, 2.0377e-08, 2.0575e-08,  ..., 3.0273e-08,\n",
      "          3.2935e-08, 3.4796e-08]],\n",
      "\n",
      "        [[1.6167e-08, 1.5402e-08, 1.4366e-08,  ..., 1.2697e-08,\n",
      "          1.3488e-08, 1.4446e-08],\n",
      "         [4.7362e-09, 4.6581e-09, 4.6606e-09,  ..., 5.3969e-09,\n",
      "          5.9847e-09, 6.7807e-09],\n",
      "         [8.4354e-09, 7.9669e-09, 7.7314e-09,  ..., 8.6294e-09,\n",
      "          8.4232e-09, 8.1428e-09],\n",
      "         ...,\n",
      "         [4.1030e-09, 5.2699e-09, 7.4418e-09,  ..., 2.3999e-08,\n",
      "          2.8149e-08, 3.1417e-08],\n",
      "         [4.6556e-08, 5.2230e-08, 5.7435e-08,  ..., 5.8663e-08,\n",
      "          5.2931e-08, 4.5609e-08],\n",
      "         [1.4272e-08, 1.1848e-08, 1.0004e-08,  ..., 1.2847e-08,\n",
      "          1.6578e-08, 2.1138e-08]],\n",
      "\n",
      "        [[1.2960e-09, 1.1537e-09, 1.1014e-09,  ..., 1.2537e-09,\n",
      "          1.2782e-09, 1.3119e-09],\n",
      "         [4.8105e-09, 5.1809e-09, 5.7419e-09,  ..., 6.6366e-09,\n",
      "          6.1740e-09, 5.5529e-09],\n",
      "         [1.2289e-09, 1.0762e-09, 9.3792e-10,  ..., 8.7763e-10,\n",
      "          8.7152e-10, 8.2800e-10],\n",
      "         ...,\n",
      "         [8.2125e-09, 7.5450e-09, 6.9481e-09,  ..., 5.8403e-09,\n",
      "          5.7574e-09, 5.6749e-09],\n",
      "         [8.7903e-10, 8.2267e-10, 8.0746e-10,  ..., 1.1744e-09,\n",
      "          1.4124e-09, 1.8184e-09],\n",
      "         [1.1135e-08, 1.1901e-08, 1.3144e-08,  ..., 1.1444e-08,\n",
      "          9.2457e-09, 7.8174e-09]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[4.2411e-08, 3.8220e-08, 3.2564e-08,  ..., 1.4270e-08,\n",
      "          1.3794e-08, 1.4756e-08],\n",
      "         [5.1324e-09, 5.1143e-09, 5.2875e-09,  ..., 7.1017e-09,\n",
      "          8.1819e-09, 9.5448e-09],\n",
      "         [2.8149e-08, 2.7917e-08, 2.6513e-08,  ..., 2.0283e-08,\n",
      "          1.9809e-08, 1.8794e-08],\n",
      "         ...,\n",
      "         [8.1524e-09, 9.8526e-09, 1.2625e-08,  ..., 2.6066e-08,\n",
      "          2.9732e-08, 3.3617e-08],\n",
      "         [1.5517e-08, 1.3649e-08, 1.2130e-08,  ..., 1.1592e-08,\n",
      "          1.3648e-08, 1.6746e-08],\n",
      "         [2.3028e-08, 2.0886e-08, 2.1586e-08,  ..., 4.8021e-08,\n",
      "          5.6076e-08, 6.3387e-08]],\n",
      "\n",
      "        [[5.9309e-09, 5.3823e-09, 4.7996e-09,  ..., 3.0120e-09,\n",
      "          2.8715e-09, 2.8690e-09],\n",
      "         [2.4270e-09, 2.7576e-09, 3.1286e-09,  ..., 3.9585e-09,\n",
      "          3.8967e-09, 3.7479e-09],\n",
      "         [2.4169e-09, 2.6087e-09, 2.7996e-09,  ..., 2.9849e-09,\n",
      "          2.9028e-09, 2.7917e-09],\n",
      "         ...,\n",
      "         [4.3051e-09, 4.4905e-09, 4.7624e-09,  ..., 5.6852e-09,\n",
      "          5.4642e-09, 5.1010e-09],\n",
      "         [8.1830e-09, 7.9539e-09, 7.5817e-09,  ..., 6.3443e-09,\n",
      "          6.4989e-09, 6.8906e-09],\n",
      "         [5.9350e-09, 6.7532e-09, 7.7363e-09,  ..., 1.1564e-08,\n",
      "          1.1920e-08, 1.2020e-08]],\n",
      "\n",
      "        [[8.0773e-09, 7.7964e-09, 7.8373e-09,  ..., 9.9427e-09,\n",
      "          1.0821e-08, 1.1745e-08],\n",
      "         [9.0691e-09, 8.9062e-09, 8.5901e-09,  ..., 8.7761e-09,\n",
      "          1.0064e-08, 1.1878e-08],\n",
      "         [1.1835e-08, 1.0240e-08, 8.6036e-09,  ..., 4.6090e-09,\n",
      "          4.4387e-09, 4.4887e-09],\n",
      "         ...,\n",
      "         [3.5711e-08, 4.3672e-08, 5.1028e-08,  ..., 5.4590e-08,\n",
      "          4.9700e-08, 4.4054e-08],\n",
      "         [7.7459e-09, 6.5902e-09, 5.7458e-09,  ..., 4.9677e-09,\n",
      "          5.3808e-09, 5.9808e-09],\n",
      "         [4.4536e-08, 4.4419e-08, 4.4083e-08,  ..., 4.7307e-08,\n",
      "          4.9729e-08, 5.1157e-08]]])}, 5: {'step': 75600, 'exp_avg': tensor([ 8.5611e-11, -1.9866e-11, -1.9211e-11, -6.0158e-11,  3.3744e-11,\n",
      "        -7.4774e-12,  9.3916e-12,  7.7833e-12,  1.2587e-10, -3.5832e-11,\n",
      "        -3.6023e-11, -6.7938e-11, -5.5068e-12, -6.3604e-11, -5.3639e-11,\n",
      "         1.0661e-11, -2.2410e-13,  4.7746e-12,  2.9385e-12, -1.8192e-11,\n",
      "         2.6275e-11,  3.5146e-11, -2.2430e-11,  3.9579e-11, -5.3417e-11,\n",
      "        -8.4740e-12,  2.0555e-11, -5.4930e-11,  1.1281e-11, -7.3585e-12,\n",
      "        -3.0008e-11,  3.9406e-12,  1.1539e-11,  1.3621e-11,  8.8587e-12,\n",
      "        -8.0498e-11,  2.1428e-11, -3.7006e-12,  1.2952e-11,  4.4874e-11,\n",
      "        -9.9928e-12, -7.6796e-11, -4.0110e-11, -1.7090e-11, -5.6455e-12,\n",
      "        -7.7656e-11,  6.9588e-12,  3.5398e-11, -5.9020e-11, -5.2292e-12,\n",
      "         2.7009e-11, -3.2263e-11, -1.0362e-11, -8.0353e-12,  9.1833e-12,\n",
      "        -4.0105e-11, -4.7287e-11,  1.4697e-11, -2.0837e-11,  1.8262e-10,\n",
      "        -8.6869e-12, -1.3009e-10, -1.0216e-10,  2.9579e-11, -1.1117e-14,\n",
      "         5.3225e-12,  3.8924e-11, -4.2268e-12,  4.5081e-12,  3.4568e-11,\n",
      "         1.7123e-11, -1.7335e-11,  8.8276e-12,  2.0619e-11, -6.2507e-12,\n",
      "         3.6149e-12, -2.5157e-11,  8.7083e-12,  1.1596e-11,  5.2893e-11,\n",
      "         6.2180e-11,  2.3837e-11,  6.4277e-12,  1.0921e-11,  9.5009e-11,\n",
      "         5.4203e-11,  1.1435e-10, -4.5534e-12,  9.9924e-12, -5.7085e-12,\n",
      "        -4.4813e-11, -1.4430e-10, -2.3376e-11, -3.3002e-11,  3.9609e-12,\n",
      "        -3.5050e-11,  3.9527e-11, -4.3219e-11, -4.1129e-12, -2.0445e-11,\n",
      "         1.4993e-11,  2.2246e-11, -4.3594e-11, -1.6187e-12,  3.7518e-11,\n",
      "         8.5722e-12,  5.7243e-11, -3.3037e-11, -3.7036e-11,  6.3714e-12,\n",
      "         1.3488e-10,  2.9672e-11, -6.0731e-11,  6.2269e-11,  1.1263e-10,\n",
      "        -2.5665e-11,  3.6279e-11, -4.4687e-12, -2.6541e-11,  7.2536e-11,\n",
      "        -4.5737e-11,  7.8318e-11,  5.4301e-12,  5.6029e-14, -5.5989e-12,\n",
      "         3.9502e-11,  2.5634e-13,  3.4930e-12]), 'exp_avg_sq': tensor([5.1520e-20, 7.1362e-20, 1.6189e-20, 4.3274e-20, 2.2681e-20, 3.5535e-20,\n",
      "        4.1166e-20, 6.5774e-20, 6.6474e-20, 3.7751e-20, 3.6146e-20, 2.7474e-19,\n",
      "        4.8002e-20, 5.8929e-20, 4.4148e-20, 2.4277e-20, 2.7461e-20, 3.0624e-20,\n",
      "        6.4553e-20, 7.9437e-20, 9.9948e-20, 3.5690e-20, 7.4415e-20, 1.9187e-20,\n",
      "        4.8654e-20, 3.5612e-20, 1.8497e-20, 5.0558e-20, 3.9878e-20, 8.6289e-20,\n",
      "        9.4486e-20, 3.2728e-20, 9.0371e-20, 4.1684e-20, 2.6513e-20, 6.2390e-20,\n",
      "        7.2230e-20, 3.4452e-20, 2.6457e-20, 3.5551e-20, 1.1027e-19, 6.3564e-20,\n",
      "        3.3772e-20, 4.7381e-20, 1.1503e-19, 9.0953e-20, 1.2127e-20, 4.8238e-20,\n",
      "        1.7252e-19, 1.1110e-19, 4.3833e-20, 3.5778e-20, 4.5397e-20, 9.1253e-21,\n",
      "        4.9300e-20, 3.6441e-20, 7.2401e-20, 9.3579e-20, 5.7889e-20, 1.9163e-19,\n",
      "        4.8754e-20, 1.1737e-19, 9.7011e-20, 7.6745e-20, 5.5074e-20, 1.2672e-19,\n",
      "        8.3816e-20, 3.6945e-20, 5.9782e-20, 5.0708e-20, 3.4118e-20, 6.2635e-20,\n",
      "        7.4643e-21, 7.3932e-20, 1.3225e-20, 4.1825e-20, 1.5353e-19, 5.6139e-20,\n",
      "        4.1181e-20, 2.3757e-20, 7.3791e-20, 4.6431e-20, 9.0108e-20, 4.8265e-20,\n",
      "        6.9802e-20, 8.2275e-20, 1.5255e-19, 2.2851e-20, 9.4219e-20, 9.9371e-21,\n",
      "        3.0390e-20, 6.2449e-20, 4.9267e-20, 5.2169e-20, 6.0173e-20, 3.5274e-20,\n",
      "        1.2072e-19, 7.9308e-20, 1.7596e-20, 5.9522e-20, 4.5406e-20, 3.6500e-20,\n",
      "        1.2316e-19, 6.4911e-20, 4.4987e-20, 6.4188e-20, 9.3691e-20, 7.7354e-20,\n",
      "        6.9380e-20, 2.4072e-20, 1.2248e-19, 7.0735e-20, 2.9301e-20, 2.5316e-20,\n",
      "        1.6037e-19, 1.0161e-19, 2.1755e-20, 6.6166e-20, 7.5547e-20, 1.0405e-19,\n",
      "        1.4113e-19, 5.8642e-20, 2.9466e-20, 4.5113e-20, 5.6011e-20, 9.9019e-20,\n",
      "        2.2105e-20, 4.2231e-20])}, 6: {'step': 75600, 'exp_avg': tensor([ 1.2200e-03,  1.7747e-04, -2.3551e-04,  5.4762e-04, -6.6900e-04,\n",
      "        -7.9256e-04,  2.3199e-04, -3.4557e-04, -5.7289e-05, -1.4989e-04,\n",
      "        -3.2846e-04,  1.2270e-03, -7.0653e-04, -1.1717e-03,  6.8492e-04,\n",
      "         2.1041e-04,  2.4652e-04,  4.2479e-04,  5.2013e-04,  2.0709e-05,\n",
      "        -3.8197e-04, -4.8416e-04, -2.5848e-04,  9.7624e-04, -1.6484e-03,\n",
      "        -5.6077e-04, -1.1997e-03, -1.1071e-04,  1.6017e-04,  1.0290e-04,\n",
      "        -3.8216e-04, -2.5915e-05, -9.1707e-04, -1.1013e-05, -6.0477e-04,\n",
      "        -1.2485e-04,  1.0805e-04, -8.4799e-04,  2.6236e-04,  6.5773e-04,\n",
      "        -1.1819e-04,  4.5829e-04, -3.8484e-04,  1.0111e-04, -8.6070e-05,\n",
      "        -3.3646e-04,  7.5375e-04,  3.1061e-04,  7.6014e-04,  1.1229e-04,\n",
      "        -1.4346e-03,  6.9338e-04,  3.8082e-04, -1.5738e-04,  7.7783e-04,\n",
      "         1.6644e-04,  8.3206e-04, -1.0815e-04, -1.6005e-03, -2.3233e-04,\n",
      "         1.1719e-04, -1.7380e-04,  1.2583e-04, -1.0908e-03, -1.0252e-04,\n",
      "         5.8702e-05, -7.5351e-05,  9.9098e-04,  7.3957e-04,  1.1223e-03,\n",
      "         1.0064e-03,  2.7945e-04, -1.0372e-03, -3.5398e-04,  8.5711e-04,\n",
      "        -3.7214e-04,  1.1615e-04,  1.4661e-03, -5.2628e-04,  2.7394e-04,\n",
      "        -7.6115e-04,  1.4890e-04, -4.1842e-04, -5.6749e-04, -8.1340e-04,\n",
      "         1.0931e-03, -2.9795e-05, -6.5116e-04,  5.0450e-04, -3.2575e-04,\n",
      "         4.2050e-04,  2.2205e-04, -7.4494e-05, -6.6494e-04, -2.5823e-04,\n",
      "         2.7757e-04, -7.4256e-04,  5.3519e-05,  1.3726e-04, -1.2978e-03,\n",
      "         1.1765e-03,  2.3567e-04,  5.2135e-04, -1.1098e-03, -2.6270e-04,\n",
      "         1.9454e-04,  5.2969e-04,  1.8099e-04,  2.4874e-04,  7.6126e-06,\n",
      "        -1.5545e-03, -8.5966e-04,  5.4040e-04,  3.1829e-04, -3.5661e-05,\n",
      "        -9.0640e-04, -1.0363e-03,  1.5639e-03, -7.9663e-04, -1.1038e-03,\n",
      "         1.1689e-03, -2.0103e-04, -1.2487e-03,  2.8401e-04,  9.2926e-04,\n",
      "         4.9683e-04, -4.4336e-04, -2.5998e-04]), 'exp_avg_sq': tensor([1.0259e-05, 1.7534e-05, 2.2710e-05, 1.1708e-05, 5.2333e-06, 2.0722e-05,\n",
      "        8.7812e-06, 1.4420e-05, 1.1430e-05, 6.5971e-06, 1.5332e-05, 1.9512e-05,\n",
      "        1.9133e-05, 1.5838e-05, 1.7944e-05, 9.6765e-06, 5.3185e-06, 1.3915e-05,\n",
      "        2.3204e-05, 1.4682e-05, 1.5385e-05, 1.6358e-05, 9.3870e-06, 1.2186e-05,\n",
      "        1.9201e-05, 9.6046e-06, 1.2557e-05, 1.0862e-05, 2.2198e-05, 7.2984e-06,\n",
      "        7.3094e-06, 1.8417e-05, 1.7129e-05, 1.1584e-05, 9.7321e-06, 2.1397e-05,\n",
      "        1.1244e-05, 1.4585e-05, 1.1896e-05, 8.8586e-06, 9.7973e-06, 2.1160e-05,\n",
      "        8.1038e-06, 2.0008e-05, 1.5684e-05, 9.4088e-06, 2.1576e-05, 1.6442e-05,\n",
      "        2.5112e-05, 1.2063e-05, 1.7114e-05, 1.4383e-05, 1.2649e-05, 1.2509e-05,\n",
      "        2.5648e-05, 2.2460e-05, 2.2144e-05, 1.9782e-05, 1.6773e-05, 1.6082e-05,\n",
      "        6.0858e-06, 1.6853e-05, 1.1439e-05, 8.0648e-06, 5.8707e-06, 2.6288e-05,\n",
      "        1.5185e-05, 1.1028e-05, 1.6465e-05, 1.7828e-05, 1.2697e-05, 1.3720e-05,\n",
      "        2.1918e-05, 1.9099e-05, 1.2693e-05, 1.9890e-05, 1.8249e-05, 2.0773e-05,\n",
      "        2.3518e-05, 4.7487e-06, 4.2398e-05, 1.6482e-05, 2.2084e-05, 2.9589e-05,\n",
      "        1.1593e-05, 1.6908e-05, 1.7462e-05, 1.8875e-05, 1.7982e-05, 1.1069e-05,\n",
      "        1.6188e-05, 2.3689e-05, 1.4246e-05, 9.1787e-06, 1.6534e-05, 1.4968e-05,\n",
      "        1.1853e-05, 1.3554e-05, 3.2530e-06, 2.8152e-05, 1.5833e-05, 1.2524e-05,\n",
      "        1.2514e-05, 3.1798e-05, 1.5930e-05, 1.5030e-05, 1.5545e-05, 1.6557e-05,\n",
      "        1.2612e-05, 1.7060e-05, 2.2032e-05, 2.0475e-05, 6.3386e-06, 1.4787e-05,\n",
      "        1.9538e-05, 1.6215e-05, 7.5356e-06, 2.3640e-05, 1.3648e-05, 1.9166e-05,\n",
      "        1.2084e-05, 1.5216e-05, 1.3022e-05, 1.4292e-05, 1.2718e-05, 2.1074e-05,\n",
      "        1.6147e-05, 2.7232e-05])}, 7: {'step': 75600, 'exp_avg': tensor([ 1.3306e-03,  4.1127e-04, -3.8661e-04,  2.1891e-04, -3.8443e-04,\n",
      "        -7.9283e-04, -8.5773e-05, -2.9250e-04, -6.9445e-05, -1.9893e-04,\n",
      "        -1.4333e-04,  7.9429e-04, -1.1781e-03, -6.7183e-04,  4.0402e-04,\n",
      "         2.5054e-04,  1.8789e-04,  4.7862e-04,  3.9743e-04, -2.1802e-04,\n",
      "        -5.8881e-04, -4.3658e-04, -3.5538e-07,  1.0007e-03, -9.7603e-04,\n",
      "        -1.8666e-04, -9.7853e-04,  1.1801e-04, -3.0312e-06, -8.2335e-05,\n",
      "        -9.1926e-05, -2.3444e-04, -5.2964e-04,  3.5695e-04, -7.1994e-04,\n",
      "        -2.6863e-04, -5.5197e-05, -3.8760e-04,  2.3452e-04,  6.9519e-04,\n",
      "        -4.2324e-05,  4.0167e-06, -2.0270e-04, -3.1066e-04, -5.0323e-04,\n",
      "        -4.6838e-04, -5.4852e-05,  4.8742e-04,  3.7499e-04,  1.0721e-04,\n",
      "        -9.4005e-04,  3.3240e-04,  4.0563e-04, -7.1756e-05,  3.8617e-04,\n",
      "        -4.3899e-04,  6.7493e-04, -7.6107e-04, -8.5706e-04,  3.0511e-04,\n",
      "        -8.4198e-05, -6.8840e-04,  4.5745e-04, -8.2456e-04, -1.5494e-05,\n",
      "         6.6405e-05,  8.4452e-05,  5.1823e-04,  4.6229e-04,  8.3250e-04,\n",
      "         9.2031e-04,  4.0112e-05, -5.6708e-04, -3.8258e-04,  5.1540e-04,\n",
      "        -1.7279e-04,  2.0353e-04,  6.4658e-04, -3.5087e-04,  5.0088e-04,\n",
      "        -6.0583e-04, -3.4907e-04, -2.9408e-04, -5.3781e-04, -6.7469e-04,\n",
      "        -1.2108e-05, -5.5054e-04, -4.7177e-04,  4.2664e-04, -2.6441e-04,\n",
      "         3.9025e-04,  1.0655e-04, -1.1257e-04, -1.1111e-04, -4.9659e-05,\n",
      "        -6.7563e-06, -4.3832e-04, -6.3315e-05,  4.6843e-04, -6.6669e-04,\n",
      "         8.5946e-04,  7.0688e-05,  3.9963e-06, -7.8433e-04,  3.2527e-05,\n",
      "         9.9045e-05,  2.6923e-05, -8.6895e-05, -5.8803e-05, -5.7858e-07,\n",
      "        -1.0480e-03, -8.8464e-04,  4.4377e-04, -3.5346e-05, -4.2761e-05,\n",
      "        -5.0943e-04, -8.7475e-04,  9.2186e-04, -8.5312e-04, -1.3691e-03,\n",
      "         4.1766e-04,  2.1321e-04, -1.2909e-03,  8.7483e-05,  6.5238e-04,\n",
      "        -5.4703e-05, -4.8636e-04, -4.2603e-04]), 'exp_avg_sq': tensor([1.2360e-05, 7.9830e-06, 7.1267e-06, 7.3324e-06, 5.9948e-06, 1.1236e-05,\n",
      "        8.0273e-06, 7.5386e-06, 7.9730e-06, 8.3715e-06, 8.4063e-06, 9.2493e-06,\n",
      "        8.8136e-06, 9.0378e-06, 8.3342e-06, 5.0828e-06, 5.3506e-06, 5.3349e-06,\n",
      "        8.4599e-06, 9.7768e-06, 9.3198e-06, 1.2079e-05, 6.1532e-06, 9.7025e-06,\n",
      "        1.1518e-05, 8.0290e-06, 7.4400e-06, 8.2946e-06, 8.1287e-06, 9.2268e-06,\n",
      "        7.7433e-06, 6.3917e-06, 8.1546e-06, 8.2410e-06, 6.3782e-06, 1.1285e-05,\n",
      "        1.1663e-05, 5.5735e-06, 6.2611e-06, 1.1940e-05, 7.2850e-06, 1.0277e-05,\n",
      "        8.4499e-06, 1.1172e-05, 1.4093e-05, 7.5707e-06, 5.8364e-06, 8.8499e-06,\n",
      "        1.0486e-05, 1.1064e-05, 1.0618e-05, 7.6110e-06, 7.4853e-06, 5.3745e-06,\n",
      "        7.6816e-06, 9.5998e-06, 9.9945e-06, 1.2940e-05, 1.0101e-05, 1.0137e-05,\n",
      "        6.7265e-06, 1.1497e-05, 5.9181e-06, 9.9883e-06, 6.6883e-06, 1.0515e-05,\n",
      "        9.7171e-06, 7.3605e-06, 8.8178e-06, 6.7537e-06, 8.7205e-06, 1.0571e-05,\n",
      "        6.7840e-06, 9.6916e-06, 6.1619e-06, 8.6081e-06, 9.5792e-06, 6.7636e-06,\n",
      "        1.6054e-05, 9.4632e-06, 1.2186e-05, 7.0280e-06, 9.1383e-06, 1.1947e-05,\n",
      "        7.4150e-06, 9.9885e-06, 6.8965e-06, 7.1418e-06, 9.1278e-06, 5.6465e-06,\n",
      "        8.3379e-06, 1.2936e-05, 6.0373e-06, 1.0533e-05, 8.6840e-06, 7.3475e-06,\n",
      "        1.0478e-05, 6.6605e-06, 7.5104e-06, 7.1266e-06, 8.4785e-06, 6.8919e-06,\n",
      "        8.3015e-06, 1.2105e-05, 8.0702e-06, 7.1082e-06, 8.8804e-06, 1.5601e-05,\n",
      "        9.5240e-06, 9.2434e-06, 1.0010e-05, 9.7338e-06, 7.0279e-06, 6.9233e-06,\n",
      "        9.8671e-06, 9.9042e-06, 6.9674e-06, 9.6310e-06, 9.9633e-06, 1.3007e-05,\n",
      "        8.3336e-06, 6.8574e-06, 9.4537e-06, 7.7548e-06, 5.8505e-06, 9.1970e-06,\n",
      "        8.5429e-06, 1.0818e-05])}, 8: {'step': 75600, 'exp_avg': tensor([[[ 4.7013e-06,  6.6667e-06,  7.9003e-06,  ...,  2.0542e-06,\n",
      "           1.8836e-06,  2.7828e-06],\n",
      "         [ 3.1878e-06,  5.3512e-07, -1.8431e-06,  ..., -1.0157e-05,\n",
      "          -1.0535e-05, -1.0975e-05],\n",
      "         [-1.5214e-06, -1.9882e-06, -2.8214e-06,  ..., -7.6854e-06,\n",
      "          -9.4263e-06, -1.1521e-05],\n",
      "         ...,\n",
      "         [-4.8692e-06,  5.3352e-07,  6.8483e-06,  ...,  2.1110e-05,\n",
      "           1.9418e-05,  1.7685e-05],\n",
      "         [-4.3249e-06, -3.7977e-06, -3.1699e-06,  ..., -1.4349e-06,\n",
      "          -9.7996e-07, -4.1722e-07],\n",
      "         [-1.0618e-05, -1.0302e-05, -9.5258e-06,  ...,  3.1065e-06,\n",
      "           8.6196e-06,  1.3396e-05]],\n",
      "\n",
      "        [[-8.6453e-06, -9.0978e-06, -7.9651e-06,  ..., -7.8003e-06,\n",
      "          -9.7797e-06, -1.2923e-05],\n",
      "         [-9.0004e-06, -5.0839e-06, -1.9089e-06,  ...,  3.0258e-06,\n",
      "           4.3441e-06,  6.6243e-06],\n",
      "         [-8.1262e-07, -1.0745e-06, -1.4454e-06,  ..., -1.6388e-06,\n",
      "          -1.3174e-06, -1.7186e-06],\n",
      "         ...,\n",
      "         [-7.7613e-06, -4.3267e-06, -5.1858e-06,  ..., -2.9399e-05,\n",
      "          -2.8399e-05, -2.0843e-05],\n",
      "         [-1.8699e-06, -1.9959e-06, -2.5771e-06,  ..., -5.7270e-06,\n",
      "          -6.3165e-06, -5.4931e-06],\n",
      "         [-1.1782e-05, -1.2911e-05, -1.2469e-05,  ..., -1.3946e-05,\n",
      "          -1.4385e-05, -1.4958e-05]],\n",
      "\n",
      "        [[-5.5056e-06, -2.3847e-07,  5.7416e-06,  ...,  1.6564e-05,\n",
      "           1.5955e-05,  1.4878e-05],\n",
      "         [-1.0818e-05, -1.1296e-05, -1.1012e-05,  ..., -7.5288e-06,\n",
      "          -5.7152e-06, -3.2876e-06],\n",
      "         [ 2.8356e-07,  1.6997e-07, -1.2930e-07,  ..., -2.8765e-06,\n",
      "          -3.7532e-06, -4.4121e-06],\n",
      "         ...,\n",
      "         [ 3.2229e-06,  2.3574e-06, -8.0761e-07,  ..., -2.9343e-06,\n",
      "           8.3140e-08,  3.3400e-06],\n",
      "         [-2.0152e-06, -2.1562e-06, -2.1165e-06,  ..., -1.0086e-06,\n",
      "          -8.8944e-07, -1.3749e-06],\n",
      "         [ 4.7528e-06,  4.9411e-06,  5.0897e-06,  ...,  6.9526e-06,\n",
      "           8.0993e-06,  1.0113e-05]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.1322e-05, -1.4425e-05, -1.6704e-05,  ..., -2.0990e-05,\n",
      "          -1.7590e-05, -1.1813e-05],\n",
      "         [ 1.1805e-07,  6.3100e-07,  2.3663e-07,  ...,  8.6482e-06,\n",
      "           1.0344e-05,  1.0976e-05],\n",
      "         [ 1.2075e-06,  1.0779e-06,  1.2907e-06,  ...,  9.1474e-07,\n",
      "           3.7044e-07, -4.6648e-07],\n",
      "         ...,\n",
      "         [-5.4021e-05, -6.2221e-05, -6.4816e-05,  ..., -2.3554e-05,\n",
      "          -9.3083e-06,  3.6164e-06],\n",
      "         [ 1.7312e-07,  6.2107e-07,  1.6589e-06,  ...,  4.4637e-06,\n",
      "           4.4898e-06,  4.9988e-06],\n",
      "         [ 1.0263e-05,  2.5640e-06, -5.2781e-06,  ..., -2.3479e-05,\n",
      "          -2.4654e-05, -2.4409e-05]],\n",
      "\n",
      "        [[-1.0293e-05, -3.5906e-06,  1.9798e-06,  ...,  2.5926e-05,\n",
      "           2.8257e-05,  2.7236e-05],\n",
      "         [-1.2773e-05, -1.4049e-05, -1.5487e-05,  ..., -5.5592e-06,\n",
      "           3.3709e-06,  1.3361e-05],\n",
      "         [ 4.4415e-06,  4.4054e-06,  4.4765e-06,  ...,  1.4520e-06,\n",
      "          -7.0994e-07,  1.2336e-06],\n",
      "         ...,\n",
      "         [-3.3027e-05, -3.6732e-05, -3.9527e-05,  ..., -2.8419e-05,\n",
      "          -1.5508e-05, -6.0769e-06],\n",
      "         [-6.6173e-06, -6.9307e-06, -6.3682e-06,  ..., -2.4429e-06,\n",
      "          -2.0652e-06, -2.1557e-06],\n",
      "         [-1.3096e-06,  2.7465e-07,  2.8718e-07,  ..., -1.0697e-05,\n",
      "          -1.5096e-05, -1.7327e-05]],\n",
      "\n",
      "        [[ 5.6691e-06,  1.3574e-05,  2.2179e-05,  ...,  2.5111e-05,\n",
      "           2.0852e-05,  1.8010e-05],\n",
      "         [ 1.7193e-05,  1.7512e-05,  1.7670e-05,  ...,  7.5209e-06,\n",
      "           7.4351e-06,  8.3042e-06],\n",
      "         [ 7.7085e-07,  5.4812e-07,  2.9277e-07,  ...,  3.5429e-07,\n",
      "           5.5623e-07,  8.0821e-07],\n",
      "         ...,\n",
      "         [-2.2668e-05, -2.1649e-05, -2.0915e-05,  ..., -1.1075e-05,\n",
      "          -4.6267e-06,  3.2059e-06],\n",
      "         [ 3.7219e-06,  3.3867e-06,  3.3584e-06,  ...,  3.6608e-06,\n",
      "           4.4257e-06,  5.1015e-06],\n",
      "         [-1.9762e-05, -1.6866e-05, -1.4844e-05,  ..., -5.8278e-06,\n",
      "          -5.8951e-06, -8.5708e-06]]]), 'exp_avg_sq': tensor([[[8.1476e-09, 9.7366e-09, 1.1167e-08,  ..., 9.3415e-09,\n",
      "          8.1689e-09, 7.5693e-09],\n",
      "         [4.5895e-09, 5.4957e-09, 6.5378e-09,  ..., 9.9060e-09,\n",
      "          9.6128e-09, 9.1065e-09],\n",
      "         [6.3240e-09, 6.7732e-09, 7.0490e-09,  ..., 7.9508e-09,\n",
      "          8.6218e-09, 9.6862e-09],\n",
      "         ...,\n",
      "         [1.8059e-08, 2.0653e-08, 2.3037e-08,  ..., 1.7349e-08,\n",
      "          1.4599e-08, 1.2634e-08],\n",
      "         [5.1514e-09, 5.6378e-09, 6.3867e-09,  ..., 7.1384e-09,\n",
      "          6.3145e-09, 5.3793e-09],\n",
      "         [9.1998e-09, 7.6911e-09, 6.6584e-09,  ..., 6.3187e-09,\n",
      "          6.6262e-09, 6.8330e-09]],\n",
      "\n",
      "        [[3.9860e-08, 3.6649e-08, 3.6594e-08,  ..., 4.1366e-08,\n",
      "          4.1006e-08, 4.0261e-08],\n",
      "         [9.7257e-09, 8.3997e-09, 9.0089e-09,  ..., 8.5699e-09,\n",
      "          1.0286e-08, 1.2508e-08],\n",
      "         [6.3490e-09, 5.8835e-09, 5.3545e-09,  ..., 4.6794e-09,\n",
      "          4.9400e-09, 5.3231e-09],\n",
      "         ...,\n",
      "         [2.2692e-08, 1.8182e-08, 1.6945e-08,  ..., 2.3984e-08,\n",
      "          2.7349e-08, 3.2032e-08],\n",
      "         [6.5994e-09, 6.1137e-09, 6.0702e-09,  ..., 7.1276e-09,\n",
      "          7.2863e-09, 7.1915e-09],\n",
      "         [7.7628e-08, 8.1322e-08, 8.3982e-08,  ..., 7.7296e-08,\n",
      "          7.4271e-08, 7.1998e-08]],\n",
      "\n",
      "        [[1.5446e-08, 1.4844e-08, 1.4258e-08,  ..., 1.4019e-08,\n",
      "          1.3761e-08, 1.3297e-08],\n",
      "         [5.6289e-09, 5.5918e-09, 5.5687e-09,  ..., 6.4517e-09,\n",
      "          6.4860e-09, 6.1832e-09],\n",
      "         [1.2864e-09, 1.6475e-09, 2.1214e-09,  ..., 6.0735e-09,\n",
      "          7.5091e-09, 8.8219e-09],\n",
      "         ...,\n",
      "         [2.2993e-08, 2.0601e-08, 1.8700e-08,  ..., 3.0753e-08,\n",
      "          3.4489e-08, 3.5705e-08],\n",
      "         [2.4626e-09, 2.2959e-09, 2.3294e-09,  ..., 3.5935e-09,\n",
      "          3.6528e-09, 3.3671e-09],\n",
      "         [1.8936e-08, 1.9964e-08, 2.1275e-08,  ..., 2.3271e-08,\n",
      "          2.3063e-08, 2.3194e-08]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.2419e-08, 1.2517e-08, 1.2073e-08,  ..., 1.1028e-08,\n",
      "          1.0741e-08, 1.0431e-08],\n",
      "         [5.0520e-09, 5.0573e-09, 5.2306e-09,  ..., 6.0584e-09,\n",
      "          5.8496e-09, 5.6578e-09],\n",
      "         [6.2170e-09, 7.0234e-09, 7.6514e-09,  ..., 1.0266e-08,\n",
      "          1.0975e-08, 1.1603e-08],\n",
      "         ...,\n",
      "         [1.4009e-08, 1.6983e-08, 2.0160e-08,  ..., 3.3628e-08,\n",
      "          3.3455e-08, 3.0031e-08],\n",
      "         [8.6615e-10, 7.0933e-10, 7.2191e-10,  ..., 2.2099e-09,\n",
      "          2.6409e-09, 3.0920e-09],\n",
      "         [1.6794e-08, 1.7000e-08, 1.7726e-08,  ..., 2.6978e-08,\n",
      "          3.0725e-08, 3.3871e-08]],\n",
      "\n",
      "        [[2.3880e-08, 2.3579e-08, 2.4111e-08,  ..., 2.6241e-08,\n",
      "          2.6176e-08, 2.6099e-08],\n",
      "         [9.8625e-09, 1.0949e-08, 1.1675e-08,  ..., 1.2818e-08,\n",
      "          1.2961e-08, 1.2827e-08],\n",
      "         [4.6218e-09, 3.7646e-09, 3.0027e-09,  ..., 2.1601e-09,\n",
      "          2.3679e-09, 2.6182e-09],\n",
      "         ...,\n",
      "         [3.0103e-08, 2.9184e-08, 2.7749e-08,  ..., 1.3968e-08,\n",
      "          1.2741e-08, 1.1911e-08],\n",
      "         [5.4658e-09, 5.5575e-09, 5.4279e-09,  ..., 3.8913e-09,\n",
      "          3.9478e-09, 4.2340e-09],\n",
      "         [1.1730e-08, 1.5979e-08, 2.0536e-08,  ..., 2.8617e-08,\n",
      "          2.7037e-08, 2.4460e-08]],\n",
      "\n",
      "        [[1.9961e-08, 1.8989e-08, 1.7926e-08,  ..., 1.6307e-08,\n",
      "          1.6003e-08, 1.5649e-08],\n",
      "         [9.8711e-09, 9.2177e-09, 8.8592e-09,  ..., 9.4232e-09,\n",
      "          8.8704e-09, 7.9858e-09],\n",
      "         [6.1764e-10, 6.7816e-10, 7.7625e-10,  ..., 1.3625e-09,\n",
      "          1.5032e-09, 1.6494e-09],\n",
      "         ...,\n",
      "         [2.4467e-08, 2.4251e-08, 2.2216e-08,  ..., 1.9379e-08,\n",
      "          2.1446e-08, 2.2897e-08],\n",
      "         [3.3780e-09, 2.6890e-09, 2.2103e-09,  ..., 1.8109e-09,\n",
      "          1.8854e-09, 1.7634e-09],\n",
      "         [6.4546e-09, 7.9265e-09, 9.5404e-09,  ..., 1.4565e-08,\n",
      "          1.5215e-08, 1.6279e-08]]])}, 9: {'step': 75600, 'exp_avg': tensor([-6.2125e-11,  4.1969e-11, -2.4691e-11,  6.6434e-11, -3.3173e-11,\n",
      "         2.7408e-11, -3.1578e-11, -1.1149e-11,  3.4888e-12, -2.5673e-11,\n",
      "         1.5757e-11,  9.1970e-12,  1.7551e-12, -4.8353e-12, -2.1475e-11,\n",
      "        -5.2217e-12, -5.2358e-13,  1.1581e-11,  4.9082e-12, -9.1115e-12,\n",
      "        -8.9640e-12,  3.4194e-12,  3.2634e-11, -6.1196e-11,  4.1660e-11,\n",
      "        -4.1830e-11,  5.3162e-11, -1.3809e-11,  5.2884e-11, -3.0910e-11,\n",
      "        -3.3818e-11, -1.6948e-11, -2.1988e-11,  7.0661e-12,  9.4488e-11,\n",
      "         1.3620e-11,  2.4337e-11, -3.1092e-12,  5.6160e-12,  8.4911e-12,\n",
      "         1.1396e-11,  1.2041e-11, -7.0113e-12,  5.3057e-11, -1.6325e-11,\n",
      "         3.6540e-12,  1.3189e-12, -2.4812e-11, -1.1214e-12,  9.6955e-12,\n",
      "        -4.0242e-12,  1.1887e-10,  1.8481e-11, -7.9902e-12, -3.9239e-12,\n",
      "         8.1583e-12, -5.8401e-11, -8.6070e-12, -6.4959e-12,  8.3441e-12,\n",
      "        -1.8737e-11, -4.7488e-12,  2.3693e-12, -5.5520e-11, -8.5118e-11,\n",
      "        -2.4030e-11,  4.3560e-11,  1.6195e-11, -1.2115e-11, -5.9021e-12,\n",
      "        -1.4312e-11,  6.5686e-11, -1.9179e-11,  5.0862e-11,  6.6514e-12,\n",
      "         2.0513e-11,  3.3800e-11,  4.7519e-12,  2.2776e-12, -1.4454e-11,\n",
      "         3.1956e-11, -2.6335e-11, -2.7364e-11,  2.3811e-11,  5.5495e-11,\n",
      "        -1.6082e-12,  1.1801e-12, -3.5194e-12, -1.9950e-11, -4.6014e-12,\n",
      "        -1.4867e-11, -1.9793e-11,  1.4318e-10, -1.5604e-12,  2.5122e-11,\n",
      "         5.9350e-11]), 'exp_avg_sq': tensor([7.1679e-20, 1.6225e-19, 5.1529e-20, 1.1290e-19, 7.3454e-20, 6.6528e-20,\n",
      "        5.7026e-20, 4.5040e-20, 1.4283e-19, 3.0077e-20, 6.7497e-20, 4.8738e-20,\n",
      "        2.3173e-20, 1.1354e-19, 6.9611e-20, 4.3061e-20, 1.0819e-20, 6.9580e-20,\n",
      "        5.5668e-20, 2.6847e-20, 2.6705e-20, 7.3622e-20, 6.1289e-20, 1.1397e-19,\n",
      "        8.0113e-20, 4.3275e-20, 5.1881e-20, 3.2299e-20, 6.5341e-20, 6.5103e-20,\n",
      "        8.3904e-20, 8.6191e-20, 2.0096e-20, 1.5179e-19, 6.3996e-20, 3.9936e-20,\n",
      "        3.2678e-20, 4.6759e-20, 2.5644e-20, 9.3762e-20, 5.4827e-20, 2.0752e-19,\n",
      "        6.3345e-20, 1.5271e-19, 1.0885e-19, 4.7244e-20, 9.2595e-20, 8.2494e-20,\n",
      "        4.2349e-20, 7.0798e-20, 3.4343e-20, 1.0849e-19, 9.2687e-20, 1.9720e-20,\n",
      "        3.0742e-20, 8.4935e-20, 4.2638e-20, 9.3152e-20, 7.3524e-20, 4.0780e-20,\n",
      "        2.9538e-20, 1.4986e-20, 4.5143e-20, 1.3320e-19, 1.1720e-19, 1.8285e-19,\n",
      "        1.1414e-19, 1.1081e-19, 3.7284e-20, 5.3024e-20, 2.0590e-20, 6.2233e-20,\n",
      "        3.7556e-20, 5.6216e-20, 4.1606e-20, 1.7123e-19, 8.3775e-20, 1.2751e-19,\n",
      "        8.9269e-20, 6.7724e-20, 3.7986e-20, 2.6306e-20, 5.3443e-20, 1.5016e-19,\n",
      "        1.1689e-19, 9.3893e-20, 1.3007e-19, 8.2442e-20, 2.6469e-20, 5.9335e-20,\n",
      "        2.9031e-20, 5.7195e-20, 8.7655e-20, 5.6777e-20, 8.2383e-20, 6.7774e-20])}, 10: {'step': 75600, 'exp_avg': tensor([-2.5938e-04, -3.1170e-04,  5.7206e-05,  3.0715e-04, -3.9378e-04,\n",
      "         1.0263e-03, -1.6198e-04,  2.2316e-04,  4.8328e-04, -4.2571e-05,\n",
      "         7.6009e-04, -2.9883e-04,  5.4726e-04, -2.1536e-04, -1.2724e-04,\n",
      "        -4.5372e-04, -4.8234e-04,  6.7758e-04, -2.9852e-04,  1.8130e-04,\n",
      "         9.7135e-05, -7.3097e-04,  3.4564e-04, -1.0386e-04, -2.8997e-04,\n",
      "         2.8532e-04,  5.8400e-04, -2.5108e-04, -9.0100e-04, -1.0722e-04,\n",
      "        -3.8892e-04,  7.9438e-05,  2.8399e-04,  1.8734e-04,  3.6610e-04,\n",
      "         5.9235e-04,  1.7655e-04, -8.0352e-04,  7.6828e-04, -7.9017e-05,\n",
      "        -9.4516e-04,  6.7402e-04, -2.1814e-05, -1.5058e-03, -2.7248e-04,\n",
      "        -4.9101e-04,  7.3605e-04, -1.1906e-04,  1.7201e-03, -2.9051e-04,\n",
      "        -3.1177e-04, -7.0821e-04,  5.4908e-05,  4.8372e-04, -4.7676e-04,\n",
      "         6.6505e-04, -3.4874e-04,  7.1081e-04,  5.9610e-04,  5.5542e-04,\n",
      "         9.3740e-04, -1.7368e-03, -2.8109e-04,  3.1684e-04, -5.5216e-04,\n",
      "        -1.3600e-04, -1.1766e-04, -5.0463e-04, -5.1838e-04,  5.4744e-05,\n",
      "        -7.8169e-04,  4.9234e-04, -1.2156e-03,  2.6922e-04, -2.2920e-04,\n",
      "        -2.8054e-04, -1.6332e-04, -1.5994e-04,  8.9914e-04, -3.8957e-04,\n",
      "        -5.5237e-04,  2.8166e-04, -5.7437e-05, -5.9176e-04, -1.2258e-03,\n",
      "         7.3308e-04, -2.7552e-04,  5.3181e-05, -1.6979e-03, -1.1563e-04,\n",
      "         9.0533e-04, -2.6395e-04, -5.6736e-04,  2.2159e-04,  5.7301e-04,\n",
      "        -6.5792e-04]), 'exp_avg_sq': tensor([1.8982e-05, 1.9901e-05, 1.9673e-05, 1.8230e-05, 1.4672e-05, 3.2432e-05,\n",
      "        7.7459e-06, 1.1783e-05, 1.4062e-05, 1.1505e-05, 1.6795e-05, 1.4652e-05,\n",
      "        1.8281e-05, 2.1481e-05, 2.1899e-05, 1.7459e-05, 2.4971e-05, 1.4356e-05,\n",
      "        6.6051e-06, 1.4444e-05, 1.8833e-05, 9.4328e-06, 1.6419e-05, 1.7827e-05,\n",
      "        2.3536e-05, 1.5427e-05, 9.8330e-06, 1.1907e-05, 2.5516e-05, 1.0659e-05,\n",
      "        2.2486e-05, 8.7588e-06, 1.3950e-05, 1.6484e-05, 1.6022e-05, 1.9005e-05,\n",
      "        9.9556e-06, 1.5959e-05, 1.5443e-05, 1.2993e-05, 1.8273e-05, 2.3333e-05,\n",
      "        1.2309e-05, 1.0171e-05, 6.3167e-06, 1.8623e-05, 1.6330e-05, 1.2078e-05,\n",
      "        2.5214e-05, 1.1836e-05, 4.6899e-06, 2.0976e-05, 1.0986e-05, 1.2175e-05,\n",
      "        1.3060e-05, 2.5748e-05, 2.3075e-05, 2.7840e-05, 1.3837e-05, 1.3844e-05,\n",
      "        2.0804e-05, 1.7113e-05, 1.3150e-05, 1.9353e-05, 2.7500e-05, 2.4035e-05,\n",
      "        1.2733e-05, 2.0262e-05, 7.9230e-06, 1.8060e-05, 1.5034e-05, 1.7551e-05,\n",
      "        1.2557e-05, 1.2090e-05, 1.4654e-05, 1.3368e-05, 1.9477e-05, 2.0307e-05,\n",
      "        1.7518e-05, 1.6502e-05, 1.7965e-05, 1.4729e-05, 2.0170e-05, 1.6923e-05,\n",
      "        1.9911e-05, 2.8747e-05, 1.2512e-05, 1.8788e-05, 2.2934e-05, 2.8809e-05,\n",
      "        1.5828e-05, 1.9302e-05, 1.6242e-05, 1.2423e-05, 1.8108e-05, 1.4389e-05])}, 11: {'step': 75600, 'exp_avg': tensor([-6.3734e-05, -2.8746e-04,  6.4610e-05, -2.6814e-04, -4.2663e-04,\n",
      "         2.2196e-04,  1.6094e-04,  3.5868e-05,  1.2454e-04, -5.5788e-04,\n",
      "         5.6217e-04, -1.4632e-04,  1.6113e-05, -4.7628e-04, -1.4427e-04,\n",
      "        -4.5961e-04, -4.0123e-04,  1.4563e-04, -3.2959e-04, -1.1935e-04,\n",
      "         4.9448e-05, -9.7096e-04,  2.5157e-04,  2.7007e-04, -2.5740e-04,\n",
      "        -8.0748e-05,  5.7091e-04,  4.5559e-06, -5.8567e-04, -1.6836e-04,\n",
      "         1.2872e-04, -3.7115e-04,  5.0769e-06,  4.9970e-05, -3.3279e-04,\n",
      "        -1.6320e-04, -2.9348e-04, -6.6229e-04, -4.4266e-06, -1.1722e-04,\n",
      "        -8.2983e-04, -3.1053e-04,  1.9901e-04, -7.7444e-04,  6.8252e-05,\n",
      "         2.5436e-05,  5.4629e-04, -5.3976e-04,  4.6038e-04, -4.4783e-04,\n",
      "         1.6728e-04, -9.2583e-04,  4.6173e-05, -1.5562e-04,  8.4858e-05,\n",
      "         9.2461e-05, -2.6699e-04,  2.2197e-04,  2.0846e-04,  3.7977e-04,\n",
      "         3.8010e-04, -8.7599e-04,  6.1321e-05, -2.8242e-04, -3.3095e-04,\n",
      "        -1.4386e-04, -3.4540e-04, -3.4585e-04, -3.9570e-04, -2.8576e-04,\n",
      "        -4.5089e-04,  1.5757e-04, -6.4206e-04, -1.5217e-04, -9.9244e-05,\n",
      "        -5.4166e-04,  4.5330e-05,  6.7034e-05,  5.1302e-05, -3.1249e-04,\n",
      "        -5.8903e-04,  8.2180e-05, -4.3820e-04, -4.5486e-04, -1.0880e-03,\n",
      "         3.6466e-04, -2.2413e-04,  7.1659e-05, -7.9160e-04, -3.4863e-04,\n",
      "         5.6624e-04,  3.2228e-04, -7.7351e-04, -2.9017e-05,  7.8041e-04,\n",
      "        -7.5006e-04]), 'exp_avg_sq': tensor([1.1279e-05, 9.6343e-06, 1.0017e-05, 7.5958e-06, 8.4811e-06, 1.2360e-05,\n",
      "        7.8396e-06, 6.0628e-06, 8.4639e-06, 6.0159e-06, 8.0039e-06, 1.0385e-05,\n",
      "        6.4164e-06, 6.6720e-06, 7.8510e-06, 7.7153e-06, 6.4195e-06, 7.8822e-06,\n",
      "        6.0619e-06, 5.5277e-06, 7.0396e-06, 1.2788e-05, 6.2560e-06, 8.7150e-06,\n",
      "        1.1188e-05, 7.8836e-06, 8.7171e-06, 7.9286e-06, 1.1115e-05, 7.9915e-06,\n",
      "        1.1558e-05, 8.2673e-06, 6.0159e-06, 1.0428e-05, 9.3839e-06, 8.1917e-06,\n",
      "        6.9260e-06, 9.0381e-06, 6.9381e-06, 8.4218e-06, 7.0509e-06, 8.9195e-06,\n",
      "        7.1016e-06, 6.4540e-06, 8.3421e-06, 5.8621e-06, 8.3691e-06, 9.3596e-06,\n",
      "        7.5166e-06, 6.9891e-06, 5.6909e-06, 1.1171e-05, 8.1392e-06, 6.0562e-06,\n",
      "        6.1005e-06, 1.1909e-05, 6.6494e-06, 9.4086e-06, 6.4624e-06, 5.1761e-06,\n",
      "        6.4137e-06, 7.4552e-06, 7.4177e-06, 1.0064e-05, 9.7867e-06, 9.6565e-06,\n",
      "        9.2975e-06, 1.0046e-05, 6.5718e-06, 9.0294e-06, 8.7082e-06, 8.3710e-06,\n",
      "        4.8268e-06, 6.4559e-06, 7.2724e-06, 8.5356e-06, 1.2763e-05, 9.1154e-06,\n",
      "        8.5313e-06, 7.6122e-06, 9.5646e-06, 7.2002e-06, 1.1387e-05, 8.8663e-06,\n",
      "        8.9383e-06, 1.0727e-05, 1.2662e-05, 7.4346e-06, 8.2202e-06, 8.6005e-06,\n",
      "        5.9972e-06, 1.0376e-05, 6.6714e-06, 6.1927e-06, 9.5102e-06, 8.6993e-06])}, 12: {'step': 75600, 'exp_avg': tensor([[[-3.9953e-06, -2.4837e-05, -4.8767e-05],\n",
      "         [ 1.2552e-04,  1.1778e-04,  7.2207e-05],\n",
      "         [ 4.8860e-05,  2.1660e-05,  3.7143e-06],\n",
      "         ...,\n",
      "         [ 4.7293e-05,  3.7439e-05,  1.5861e-05],\n",
      "         [ 2.2841e-05,  6.2224e-05,  7.7697e-05],\n",
      "         [-1.3670e-04, -1.6391e-04, -1.5941e-04]],\n",
      "\n",
      "        [[-4.9672e-05, -3.6165e-05, -3.1433e-05],\n",
      "         [-2.2408e-05, -2.5959e-05, -2.0129e-05],\n",
      "         [-2.7893e-05, -2.8414e-05, -2.9179e-05],\n",
      "         ...,\n",
      "         [-3.5037e-05, -1.7653e-05, -6.2684e-06],\n",
      "         [-5.3573e-06, -3.3778e-06, -3.4146e-06],\n",
      "         [ 3.4479e-05,  1.6153e-05,  1.2910e-05]],\n",
      "\n",
      "        [[ 3.2723e-05,  3.1052e-05,  2.9969e-05],\n",
      "         [ 2.3832e-05,  1.2570e-05,  1.0754e-05],\n",
      "         [-5.6070e-05, -9.0245e-05, -9.2594e-05],\n",
      "         ...,\n",
      "         [-3.7612e-05, -1.4444e-06,  2.4744e-05],\n",
      "         [-1.9355e-05, -6.8431e-05, -1.1096e-04],\n",
      "         [ 3.6615e-05,  1.2045e-05,  1.1750e-05]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.3877e-04, -1.3313e-04, -1.3043e-04],\n",
      "         [ 6.9475e-05,  1.7417e-04,  2.5487e-04],\n",
      "         [-5.9169e-05, -5.5964e-05, -5.1722e-05],\n",
      "         ...,\n",
      "         [ 4.6764e-05,  3.1012e-05, -7.6901e-06],\n",
      "         [-7.4711e-05, -8.9994e-05, -1.0103e-04],\n",
      "         [-5.1688e-05, -4.7846e-05, -5.2493e-05]],\n",
      "\n",
      "        [[ 1.6976e-05,  2.7934e-05,  3.8356e-05],\n",
      "         [-1.4085e-05, -1.7940e-05,  6.0075e-06],\n",
      "         [-9.3566e-05, -8.5150e-05, -5.7655e-05],\n",
      "         ...,\n",
      "         [ 1.5345e-05,  6.9735e-06,  1.2404e-05],\n",
      "         [-4.4525e-05, -8.4017e-05, -1.2148e-04],\n",
      "         [-4.8014e-05, -3.3118e-05, -2.8601e-05]],\n",
      "\n",
      "        [[ 2.1844e-05,  2.2451e-05,  2.3101e-05],\n",
      "         [ 3.5985e-05, -1.8976e-05, -4.1246e-05],\n",
      "         [ 1.0457e-05,  1.2198e-05,  1.7694e-05],\n",
      "         ...,\n",
      "         [ 5.7671e-05,  6.8524e-05,  4.0610e-05],\n",
      "         [ 3.6877e-05,  1.3623e-05, -1.9236e-05],\n",
      "         [-5.0625e-05, -4.0809e-05, -2.3567e-05]]]), 'exp_avg_sq': tensor([[[1.6364e-07, 1.8199e-07, 1.9924e-07],\n",
      "         [3.1944e-07, 3.3210e-07, 3.7655e-07],\n",
      "         [3.7548e-07, 4.7688e-07, 5.4927e-07],\n",
      "         ...,\n",
      "         [3.7027e-07, 3.4723e-07, 3.1233e-07],\n",
      "         [7.5448e-07, 8.8153e-07, 9.4222e-07],\n",
      "         [5.9493e-07, 6.2369e-07, 5.5640e-07]],\n",
      "\n",
      "        [[1.4940e-07, 1.8135e-07, 1.7615e-07],\n",
      "         [1.6347e-07, 1.6541e-07, 1.5330e-07],\n",
      "         [9.1026e-08, 8.1551e-08, 7.2881e-08],\n",
      "         ...,\n",
      "         [1.4373e-07, 1.6227e-07, 1.5456e-07],\n",
      "         [3.0974e-08, 2.5537e-08, 3.0935e-08],\n",
      "         [2.6752e-08, 2.6902e-08, 3.5465e-08]],\n",
      "\n",
      "        [[5.5183e-07, 5.0100e-07, 4.2012e-07],\n",
      "         [2.0026e-07, 1.8689e-07, 2.0924e-07],\n",
      "         [3.3581e-07, 3.3282e-07, 3.0509e-07],\n",
      "         ...,\n",
      "         [2.4531e-07, 1.9800e-07, 1.8173e-07],\n",
      "         [4.5033e-07, 3.9554e-07, 3.2691e-07],\n",
      "         [1.4205e-07, 1.3708e-07, 1.3934e-07]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[2.8031e-07, 2.8868e-07, 2.7761e-07],\n",
      "         [3.7791e-07, 3.4071e-07, 3.8766e-07],\n",
      "         [1.5299e-07, 1.3159e-07, 1.2006e-07],\n",
      "         ...,\n",
      "         [1.5029e-07, 1.1790e-07, 1.1179e-07],\n",
      "         [2.6339e-07, 3.0397e-07, 3.6788e-07],\n",
      "         [1.6122e-07, 1.7144e-07, 1.6607e-07]],\n",
      "\n",
      "        [[9.4844e-08, 9.3397e-08, 9.1633e-08],\n",
      "         [2.9262e-07, 2.3430e-07, 1.8707e-07],\n",
      "         [1.1203e-07, 1.2576e-07, 1.2067e-07],\n",
      "         ...,\n",
      "         [2.1767e-07, 2.3260e-07, 2.0457e-07],\n",
      "         [1.1892e-07, 8.7081e-08, 9.1797e-08],\n",
      "         [7.2632e-08, 8.2006e-08, 8.2110e-08]],\n",
      "\n",
      "        [[1.6533e-07, 1.3567e-07, 1.2221e-07],\n",
      "         [1.0437e-07, 1.3636e-07, 1.8467e-07],\n",
      "         [1.4197e-07, 1.5777e-07, 1.7523e-07],\n",
      "         ...,\n",
      "         [1.8198e-07, 2.0525e-07, 2.0670e-07],\n",
      "         [1.7233e-07, 1.9987e-07, 2.4164e-07],\n",
      "         [2.6428e-07, 2.7993e-07, 2.5350e-07]]])}, 13: {'step': 75600, 'exp_avg': tensor([ 4.0261e-11, -5.7869e-11, -1.2198e-11,  1.0526e-10,  1.5521e-10,\n",
      "        -4.9107e-11, -2.6133e-11,  5.4910e-11,  1.4354e-11,  1.4462e-12,\n",
      "         1.9244e-10,  6.9020e-11,  5.1738e-11, -6.7343e-11,  2.3090e-11,\n",
      "         5.9541e-11, -2.1591e-10, -1.1450e-10, -3.0185e-10, -2.3192e-11,\n",
      "         3.3499e-11,  6.6774e-11,  8.1875e-11,  4.6855e-11,  4.2512e-11,\n",
      "         1.1388e-10,  2.2836e-10,  6.6698e-11, -5.3452e-11,  1.8489e-11,\n",
      "         1.0438e-11,  3.5897e-11,  1.1309e-11,  5.0287e-12, -8.7774e-11,\n",
      "        -4.2211e-11,  5.5688e-11,  1.8303e-11, -5.2487e-11, -5.9128e-11,\n",
      "        -7.3911e-11,  2.0071e-10,  2.5489e-11, -2.3058e-11,  2.2210e-11,\n",
      "        -5.3560e-12,  8.1162e-11, -9.0540e-13,  5.0570e-11,  1.2769e-11,\n",
      "         8.7873e-12, -6.7172e-11,  8.1604e-11, -4.2328e-11, -3.1014e-11,\n",
      "         2.9410e-11,  5.0995e-11,  1.1096e-11, -3.8693e-11,  1.1495e-10,\n",
      "        -6.2347e-11, -8.7993e-11, -2.2168e-11, -1.5255e-11]), 'exp_avg_sq': tensor([4.9435e-19, 1.2948e-19, 3.6990e-19, 1.7436e-19, 2.6019e-19, 6.7308e-19,\n",
      "        2.0798e-19, 1.8445e-19, 2.0195e-19, 1.9715e-19, 4.5570e-19, 3.3555e-19,\n",
      "        4.8088e-19, 9.1770e-20, 1.4075e-19, 2.7061e-19, 3.7051e-19, 1.6209e-19,\n",
      "        4.6482e-19, 1.8419e-19, 3.8718e-19, 6.7633e-19, 3.2313e-19, 3.0753e-19,\n",
      "        3.4088e-19, 4.5772e-19, 1.7124e-19, 1.0231e-19, 2.0283e-19, 3.6655e-19,\n",
      "        2.2038e-19, 2.2221e-19, 1.1026e-19, 9.0039e-20, 4.2728e-19, 8.4260e-20,\n",
      "        1.3177e-19, 6.4538e-19, 3.8785e-19, 3.7780e-19, 3.3073e-19, 3.7550e-19,\n",
      "        7.2203e-20, 3.0415e-19, 5.0722e-20, 6.3597e-19, 2.0927e-19, 1.4512e-19,\n",
      "        2.1454e-19, 2.7439e-19, 8.2611e-19, 2.1408e-19, 1.8378e-19, 1.5917e-19,\n",
      "        7.0339e-19, 2.2770e-19, 4.2657e-19, 1.3946e-19, 1.5622e-19, 5.3797e-19,\n",
      "        4.0269e-19, 3.0202e-19, 2.0037e-19, 1.5546e-19])}, 14: {'step': 75600, 'exp_avg': tensor([ 5.9925e-04,  4.5480e-04, -6.0144e-04,  3.7278e-04,  4.3929e-04,\n",
      "         1.4277e-03,  8.3914e-04, -1.1781e-03, -7.6965e-04,  1.3719e-03,\n",
      "        -1.3410e-03, -1.8984e-03, -1.1358e-03, -1.0525e-03,  3.4131e-04,\n",
      "        -4.8105e-04,  8.9528e-04,  3.2127e-04, -1.1489e-04, -7.7990e-04,\n",
      "         1.0420e-05,  2.1695e-03, -4.1833e-04, -9.1586e-04,  1.3315e-03,\n",
      "        -7.0198e-04, -5.3474e-05, -1.0163e-03, -1.0757e-03, -6.5427e-04,\n",
      "         1.1981e-04, -3.0191e-04,  6.1517e-04, -6.5268e-04, -8.7540e-05,\n",
      "        -1.0135e-05,  7.9955e-04, -5.2610e-04,  1.2595e-03,  1.9515e-04,\n",
      "         4.0882e-04,  3.1245e-04,  1.1359e-06, -3.8911e-04,  7.3661e-04,\n",
      "        -7.5797e-04, -1.3606e-03,  2.0320e-03,  8.4474e-05, -2.8213e-04,\n",
      "         6.4793e-04, -3.7414e-04, -1.7447e-03, -7.4731e-04,  1.4591e-03,\n",
      "        -6.5938e-04,  2.2558e-04, -9.6504e-04,  3.8547e-04,  1.3050e-03,\n",
      "        -4.8973e-04,  1.6136e-03, -2.2860e-04, -1.3175e-03]), 'exp_avg_sq': tensor([4.4646e-05, 2.7419e-05, 5.5271e-05, 4.4111e-05, 4.2195e-05, 4.1653e-05,\n",
      "        5.1292e-05, 4.1832e-05, 5.1640e-05, 7.5084e-05, 5.0389e-05, 6.7365e-05,\n",
      "        3.7571e-05, 3.1247e-05, 2.6417e-05, 3.8816e-05, 4.3747e-05, 5.0906e-05,\n",
      "        4.2009e-05, 2.9235e-05, 6.8307e-05, 6.7412e-05, 6.0344e-05, 2.6442e-05,\n",
      "        4.9414e-05, 3.4313e-05, 3.2993e-05, 2.6638e-05, 2.1570e-05, 3.6860e-05,\n",
      "        4.0571e-05, 5.0782e-05, 2.8345e-05, 2.9724e-05, 4.5202e-05, 3.9759e-05,\n",
      "        4.7479e-05, 5.1742e-05, 5.9680e-05, 4.8348e-05, 5.4292e-05, 4.6259e-05,\n",
      "        3.5883e-05, 3.2934e-05, 2.1515e-05, 7.5066e-05, 4.2785e-05, 4.9858e-05,\n",
      "        4.9607e-05, 5.9913e-05, 7.5564e-05, 3.3877e-05, 3.3692e-05, 3.3387e-05,\n",
      "        8.4514e-05, 3.5750e-05, 5.8233e-05, 4.5456e-05, 4.0803e-05, 5.0358e-05,\n",
      "        3.2914e-05, 5.8988e-05, 2.5289e-05, 2.0532e-05])}, 15: {'step': 75600, 'exp_avg': tensor([-2.0270e-04,  3.8009e-04, -1.4132e-04, -1.1213e-04,  7.8915e-04,\n",
      "         5.0979e-04,  1.6347e-04, -1.1431e-03, -7.9032e-04,  9.7700e-04,\n",
      "        -7.8646e-04, -1.1671e-03, -1.2470e-03, -1.3173e-03, -8.0116e-05,\n",
      "        -7.7874e-04,  3.2902e-04, -4.0950e-04,  2.2103e-04, -1.2628e-03,\n",
      "         1.8785e-04,  1.7820e-03, -1.4872e-04, -1.7807e-03,  1.4206e-03,\n",
      "        -1.0426e-03,  9.1628e-04, -1.3223e-03, -1.2912e-03, -6.0144e-04,\n",
      "         1.2595e-04, -4.5787e-05,  2.4251e-04, -7.5856e-04, -1.1230e-03,\n",
      "        -1.9074e-04,  4.4630e-04, -2.2487e-04,  1.3707e-03, -1.3200e-04,\n",
      "         6.6222e-04,  5.2334e-04,  2.0562e-04, -1.3467e-04,  3.7106e-04,\n",
      "        -8.5412e-04, -1.9400e-03,  1.5319e-03,  1.9247e-04,  1.9793e-04,\n",
      "         1.6740e-04, -1.9173e-04, -2.1379e-03, -8.3508e-04,  1.8875e-03,\n",
      "        -1.1237e-03,  2.2150e-04, -4.7578e-04,  3.8354e-04,  1.5698e-03,\n",
      "        -5.2147e-04,  1.3689e-03, -8.6560e-04, -1.0808e-03]), 'exp_avg_sq': tensor([4.7556e-05, 2.9049e-05, 5.5124e-05, 2.9063e-05, 4.2928e-05, 3.5912e-05,\n",
      "        3.2553e-05, 3.1583e-05, 3.3494e-05, 5.2044e-05, 5.6620e-05, 3.9772e-05,\n",
      "        3.3168e-05, 1.6830e-05, 2.5347e-05, 3.6662e-05, 3.2799e-05, 3.2629e-05,\n",
      "        5.6197e-05, 3.1232e-05, 5.9758e-05, 5.2908e-05, 4.3176e-05, 3.8558e-05,\n",
      "        4.1574e-05, 7.0577e-05, 3.9756e-05, 1.8355e-05, 2.8092e-05, 3.6147e-05,\n",
      "        3.0173e-05, 3.6823e-05, 2.2994e-05, 1.7316e-05, 2.7240e-05, 2.0002e-05,\n",
      "        3.5828e-05, 4.9227e-05, 5.3495e-05, 4.6162e-05, 6.7249e-05, 3.3456e-05,\n",
      "        2.1704e-05, 5.1486e-05, 1.4104e-05, 9.5630e-05, 4.3495e-05, 2.5599e-05,\n",
      "        4.4386e-05, 5.0635e-05, 6.8586e-05, 3.6205e-05, 3.2228e-05, 1.9568e-05,\n",
      "        7.4632e-05, 4.0671e-05, 5.6519e-05, 3.0480e-05, 3.2306e-05, 4.9654e-05,\n",
      "        3.4970e-05, 4.2566e-05, 3.9698e-05, 2.0008e-05])}, 16: {'step': 75600, 'exp_avg': tensor([[ 3.0933e-07, -1.4398e-08,  7.2864e-06,  ...,  6.3466e-09,\n",
      "          9.8296e-09, -8.4982e-08],\n",
      "        [ 1.6963e-07, -5.3170e-09, -5.7278e-09,  ...,  8.9105e-07,\n",
      "          8.6581e-07,  2.4709e-06],\n",
      "        [ 2.5711e-07,  5.9798e-08,  1.1582e-07,  ..., -9.8924e-08,\n",
      "          4.3029e-06, -2.8353e-05],\n",
      "        ...,\n",
      "        [ 1.2652e-05,  2.7891e-05, -2.6062e-05,  ...,  4.3093e-07,\n",
      "          3.1182e-08,  1.2464e-07],\n",
      "        [ 1.4725e-06,  9.2031e-07,  1.5136e-07,  ..., -4.3928e-07,\n",
      "          3.9412e-06,  1.4211e-05],\n",
      "        [ 2.3221e-07, -3.0808e-06, -2.1284e-06,  ..., -8.3906e-05,\n",
      "         -1.0916e-04, -2.4456e-04]]), 'exp_avg_sq': tensor([[4.4336e-07, 3.4263e-07, 3.9083e-07,  ..., 1.7059e-07, 1.4979e-07,\n",
      "         5.2943e-08],\n",
      "        [5.8411e-08, 3.8881e-08, 1.0879e-07,  ..., 9.9745e-08, 9.6588e-08,\n",
      "         1.3151e-07],\n",
      "        [4.8779e-08, 1.2863e-07, 1.7234e-07,  ..., 2.9822e-07, 2.7255e-07,\n",
      "         3.0650e-07],\n",
      "        ...,\n",
      "        [1.1814e-06, 1.1351e-06, 1.2380e-06,  ..., 8.8987e-08, 1.2346e-07,\n",
      "         1.0809e-07],\n",
      "        [8.6256e-07, 4.6473e-07, 1.7118e-07,  ..., 1.6341e-07, 1.8682e-07,\n",
      "         4.2142e-07],\n",
      "        [1.7683e-07, 2.7226e-07, 5.4692e-07,  ..., 9.7641e-07, 5.1889e-07,\n",
      "         4.1957e-07]])}, 17: {'step': 75600, 'exp_avg': tensor([ 2.3323e-05,  1.2496e-05, -5.8713e-05, -4.5093e-04,  4.2178e-04,\n",
      "        -1.1599e-04, -3.2731e-05,  8.5158e-05,  1.6174e-04, -4.2279e-04,\n",
      "         6.6369e-04, -1.1684e-04, -1.9170e-05,  2.6719e-06,  1.8449e-04,\n",
      "        -6.2371e-05, -2.0747e-05, -2.0385e-05,  8.3953e-05, -3.1863e-04]), 'exp_avg_sq': tensor([1.3613e-06, 2.2223e-06, 3.9823e-06, 1.0615e-06, 2.2266e-06, 2.4739e-06,\n",
      "        5.3349e-07, 1.2903e-06, 2.0917e-06, 1.6747e-06, 3.0455e-06, 4.0973e-06,\n",
      "        8.8559e-07, 7.0934e-07, 3.6249e-06, 1.3562e-06, 3.4647e-07, 2.7430e-06,\n",
      "        3.3148e-06, 8.8719e-07])}}\n",
      "param_groups \t [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]}]\n"
     ]
    }
   ],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in network.state_dict():\n",
    "    print(param_tensor, \"\\t\", network.state_dict()[param_tensor].size())\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in network.optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", network.optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f81a2ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'CNN3_weights.pth'\n",
    "torch.save(network.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ddd199",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
